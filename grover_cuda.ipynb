{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMfH49boL47C3+PTdMSwK43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidkubanek/Thesis/blob/main/grover_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GROVER\n",
        "### Generate graph transformer molecular fingerprints."
      ],
      "metadata": {
        "id": "NATXVd23fu7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change version of python to more closely match the desired GROVER environment."
      ],
      "metadata": {
        "id": "aCsRgDsSfv_n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWMcIrsaNwqz",
        "outputId": "1b9794f2-137a-4870-f7c3-ec16097ca1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: --install needs <link> <name> <path> <priority>\n",
            "\n",
            "Use 'update-alternatives --help' for program usage information.\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in manual mode\n",
            "Python version:\n",
            "Python 3.8.10\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.9 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.9 [231 kB]\n",
            "Fetched 2,389 kB in 0s (18.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 123105 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.9_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.9) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.9_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.9) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.9) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "#*Add python version you wish* to list\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8\n",
        "\n",
        "# Choose one of the given alternatives:\n",
        "#!sudo update-alternatives --config python3\n",
        "# OR\n",
        "!update-alternatives --set python3 /usr/bin/python3.8\n",
        "\n",
        "# Check the result\n",
        "print('Python version:')\n",
        "!python3 --version\n",
        "\n",
        "# Attention: Install pip (... needed!)\n",
        "!sudo apt install python3-pip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download relevant packages with compatible versions."
      ],
      "metadata": {
        "id": "Xiwel4iegSlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv grover_env\n",
        "!source grover_env/bin/activate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y--0itscQW0J",
        "outputId": "71df1db5-fbef-46a4-c6f5-022bc7cc36d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.23.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 13.3 MB/s \n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 90.8 MB/s \n",
            "\u001b[?25hCollecting platformdirs<4,>=3.5.1\n",
            "  Downloading platformdirs-3.8.1-py3-none-any.whl (16 kB)\n",
            "Collecting filelock<4,>=3.12\n",
            "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: distlib, platformdirs, filelock, virtualenv\n",
            "Successfully installed distlib-0.3.6 filelock-3.12.2 platformdirs-3.8.1 virtualenv-20.23.1\n",
            "created virtual environment CPython3.8.10.final.0-64 in 512ms\n",
            "  creator CPython3Posix(dest=/content/grover_env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==23.1.2, setuptools==67.8.0, wheel==0.40.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boost\n",
        "!pip install descriptastorus\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install tensorboard\n",
        "!pip install torchvision\n",
        "!pip install rdkit\n",
        "!pip install readline\n",
        "!pip install scikit-learn\n",
        "!pip install scipy==1.5.2\n",
        "!pip install tqdm==4.32.1\n",
        "!pip install typing==3.6.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "52nyiMs8QfVd",
        "outputId": "c446a7e8-096b-4dae-b214-b8dcbc31174c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boost\n",
            "  Downloading boost-0.1.tar.gz (6.3 kB)\n",
            "Collecting Mastodon.py\n",
            "  Downloading Mastodon.py-1.8.1-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting sqlalchemy\n",
            "  Downloading SQLAlchemy-2.0.18-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 28.7 MB/s \n",
            "\u001b[?25hCollecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 90.5 MB/s \n",
            "\u001b[?25hCollecting python-magic; platform_system != \"Windows\"\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Collecting decorator>=4.0.0\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting blurhash>=1.1.4\n",
            "  Downloading blurhash-1.1.4-py2.py3-none-any.whl (5.3 kB)\n",
            "Collecting requests>=2.4.2\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))\n",
            "  Downloading greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
            "\u001b[K     |████████████████████████████████| 618 kB 95.4 MB/s \n",
            "\u001b[?25hCollecting typing-extensions>=4.2.0\n",
            "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 93.0 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 119 kB/s \n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 70.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: boost\n",
            "  Building wheel for boost (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boost: filename=boost-0.1-py3-none-any.whl size=12460 sha256=3c8ead96cfe51afeec55368e733e304e6c7f2ef47642fda2ef8c7a4da53f9eed\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/0e/9b/591d2c638d78dea35769db51d8d6fc221cbb1b4c08af979b7c\n",
            "Successfully built boost\n",
            "Installing collected packages: six, python-dateutil, python-magic, decorator, blurhash, certifi, urllib3, idna, charset-normalizer, requests, Mastodon.py, greenlet, typing-extensions, sqlalchemy, boost\n",
            "Successfully installed Mastodon.py-1.8.1 blurhash-1.1.4 boost-0.1 certifi-2023.5.7 charset-normalizer-3.2.0 decorator-5.1.1 greenlet-2.0.2 idna-3.4 python-dateutil-2.8.2 python-magic-0.4.27 requests-2.31.0 six-1.16.0 sqlalchemy-2.0.18 typing-extensions-4.7.1 urllib3-2.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting descriptastorus\n",
            "  Downloading descriptastorus-2.6.0.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 10.6 MB/s \n",
            "\u001b[?25hCollecting pandas_flavor\n",
            "  Downloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.7 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pandas>=0.23\n",
            "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 75.1 MB/s \n",
            "\u001b[?25hCollecting xarray\n",
            "  Downloading xarray-2023.1.0-py3-none-any.whl (973 kB)\n",
            "\u001b[K     |████████████████████████████████| 973 kB 91.7 MB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 79.3 MB/s \n",
            "\u001b[?25hCollecting Pillow\n",
            "  Downloading Pillow-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 65.7 MB/s \n",
            "\u001b[?25hCollecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[K     |████████████████████████████████| 341 kB 83.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->pandas_flavor->descriptastorus) (2.8.2)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[K     |████████████████████████████████| 502 kB 91.7 MB/s \n",
            "\u001b[?25hCollecting packaging>=21.3\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas_flavor->descriptastorus) (1.16.0)\n",
            "Building wheels for collected packages: descriptastorus\n",
            "  Building wheel for descriptastorus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for descriptastorus: filename=descriptastorus-2.6.0-py3-none-any.whl size=1087722 sha256=8815ba75730e58f9c55cf9a50c1eab30f56e7cd566088866b3b81cf168779dfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/9b/92/901029ebcf24b83b3366159ead1cf09735b1a0056e18281e39\n",
            "Successfully built descriptastorus\n",
            "Installing collected packages: numpy, tzdata, pytz, pandas, packaging, xarray, pandas-flavor, Pillow, rdkit, descriptastorus\n",
            "Successfully installed Pillow-10.0.0 descriptastorus-2.6.0 numpy-1.24.4 packaging-23.1 pandas-2.0.3 pandas-flavor-0.6.0 pytz-2023.3 rdkit-2023.3.2 tzdata-2023.3 xarray-2023.1.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.24.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (2.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.24.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting torch\n",
            "  Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 619.9 MB 13 kB/s \n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 102.6 MB 5.6 kB/s \n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch) (3.12.2)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 156 kB/s \n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 10 kB/s \n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 70.9 MB/s \n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 74.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.7.1)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 7.6 MB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 168.4 MB 53 kB/s \n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 173.2 MB 17 kB/s \n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 29 kB/s \n",
            "\u001b[?25hCollecting triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 63.2 MB 10 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 61.9 MB/s \n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 177.1 MB 52 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (45.2.0)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (0.34.2)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[K     |████████████████████████████████| 536 kB 60.5 MB/s \n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 68.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.0 MB 1.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: lit\n",
            "  Building wheel for lit (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93582 sha256=43ee1e8b9cc1b1c76b48695150dc8a0ed19ec35d5a00844c231a95bdd52d3668\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ab/f1/0102fea49a41c753f0e79a1a4012417d5d7ef0f93224694472\n",
            "Successfully built lit\n",
            "Installing collected packages: nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-curand-cu11, nvidia-cuda-cupti-cu11, nvidia-cudnn-cu11, MarkupSafe, jinja2, mpmath, sympy, networkx, nvidia-cuda-nvrtc-cu11, nvidia-cufft-cu11, nvidia-cusparse-cu11, nvidia-nvtx-cu11, lit, cmake, triton, nvidia-cuda-runtime-cu11, nvidia-nccl-cu11, torch\n",
            "Successfully installed MarkupSafe-2.1.3 cmake-3.26.4 jinja2-3.1.2 lit-16.0.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 9.9 MB/s \n",
            "\u001b[?25hCollecting grpcio>=1.48.2\n",
            "  Downloading grpcio-1.56.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 66.7 MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 74.2 MB/s \n",
            "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.6 MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.19.6\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[K     |████████████████████████████████| 304 kB 102.9 MB/s \n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 98.9 MB/s \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (45.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard) (0.34.2)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 99.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.24.4)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 93.7 MB/s \n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting urllib3<2.0\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 103.6 MB/s \n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 110.4 MB/s \n",
            "\u001b[?25hCollecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting zipp>=0.5\n",
            "  Downloading zipp-3.16.0-py3-none-any.whl (6.7 kB)\n",
            "Installing collected packages: grpcio, pyasn1, pyasn1-modules, cachetools, urllib3, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, protobuf, absl-py, zipp, importlib-metadata, markdown, werkzeug, tensorboard\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.3\n",
            "    Uninstalling urllib3-2.0.3:\n",
            "      Successfully uninstalled urllib3-2.0.3\n",
            "Successfully installed absl-py-1.4.0 cachetools-5.3.1 google-auth-2.22.0 google-auth-oauthlib-1.0.0 grpcio-1.56.0 importlib-metadata-6.8.0 markdown-3.4.3 oauthlib-3.2.2 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 urllib3-1.26.16 werkzeug-2.3.6 zipp-3.16.0\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.15.2-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.8 MB 83.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (10.0.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.24.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (10.2.10.91)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (1.12)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (2.14.3)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.1->torchvision) (0.34.2)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.1->torchvision) (45.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.1->torchvision) (3.26.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.1->torchvision) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.15.2\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.8/dist-packages (2023.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (10.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.24.4)\n",
            "Collecting readline\n",
            "  Downloading readline-6.2.4.1.tar.gz (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 13.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: readline\n",
            "  Building wheel for readline (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for readline: filename=readline-6.2.4.1-cp38-cp38-linux_x86_64.whl size=394282 sha256=102acffe5a49221fb5c107ba000c0b9f62e1d20d23674811ccfb586ff54a89f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/4c/c1/897579289bc84dd6547925f38958ade4494352a353397c9d82\n",
            "Successfully built readline\n",
            "Installing collected packages: readline\n",
            "Successfully installed readline-6.2.4.1\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 14.1 MB/s \n",
            "\u001b[?25hCollecting scipy>=1.5.0\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.24.4)\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 73.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: scipy, threadpoolctl, joblib, scikit-learn\n",
            "Successfully installed joblib-1.3.1 scikit-learn-1.3.0 scipy-1.10.1 threadpoolctl-3.1.0\n",
            "Collecting scipy==1.5.2\n",
            "  Downloading scipy-1.5.2-cp38-cp38-manylinux1_x86_64.whl (25.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.7 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from scipy==1.5.2) (1.24.4)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "Successfully installed scipy-1.5.2\n",
            "Collecting tqdm==4.32.1\n",
            "  Downloading tqdm-4.32.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.32.1\n",
            "Collecting typing==3.6.4\n",
            "  Downloading typing-3.6.4-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: typing\n",
            "Successfully installed typing-3.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run GROVER repo"
      ],
      "metadata": {
        "id": "pwgEATOeWHr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/davidkubanek/grover.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrh_te0zN0pa",
        "outputId": "77e0b85d-af62-4606-b7a3-49c33e45baea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'grover'...\n",
            "remote: Enumerating objects: 278, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (175/175), done.\u001b[K\n",
            "remote: Total 278 (delta 31), reused 168 (delta 19), pack-reused 82\u001b[K\n",
            "Receiving objects: 100% (278/278), 17.68 MiB | 21.01 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd grover"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b41zhgB6fAef",
        "outputId": "d21a927a-ba86-4042-f5e0-b482aea175e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/grover\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "elYMcsEhZd1f",
        "outputId": "c5a7c570-eef6-4b1e-9631-a333f133b23a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "re8a3FrJg8ZJ",
        "outputId": "2fff885c-f077-4133-c568-4fdee1e14921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "Ol_ZMUAGiC_z",
        "outputId": "874e7ceb-b206-433e-df95-6ebe9d769abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mgrover\u001b[0m/  \u001b[01;34mgrover_env\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-training\n",
        "Not necessary if using a pre-trained model grover_base.pt/grover_large.pt checkpoint. If running pre-training from scratch, the motif and atom/bond feature extraction steps prior to pre-training would also have to be run. The present pre-training works for the tryout.csv data."
      ],
      "metadata": {
        "id": "l2wIqutpjilC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py pretrain \\\n",
        "               --data_path exampledata/pretrain/tryout \\\n",
        "               --save_dir model/tryout \\\n",
        "               --atom_vocab_path exampledata/pretrain/tryout_atom_vocab.pkl \\\n",
        "               --bond_vocab_path exampledata/pretrain/tryout_bond_vocab.pkl \\\n",
        "               --batch_size 32 \\\n",
        "               --dropout 0.1 \\\n",
        "               --depth 5 \\\n",
        "               --num_attn_head 1 \\\n",
        "               --hidden_size 100 \\\n",
        "               --epochs 3 \\\n",
        "               --init_lr 0.0002 \\\n",
        "               --max_lr 0.0004 \\\n",
        "               --final_lr 0.0001 \\\n",
        "               --weight_decay 0.0000001 \\\n",
        "               --activation PReLU \\\n",
        "               --backbone gtrans \\\n",
        "               --embedding_output_type both"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsqzEKeeWKT6",
        "outputId": "010ee062-f663-463d-8190-5a9025af99f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\n",
            "Namespace(activation='PReLU', atom_vocab_path='exampledata/pretrain/tryout_atom_vocab.pkl', backbone='gtrans', batch_size=32, bias=False, bond_drop_rate=0, bond_vocab_path='exampledata/pretrain/tryout_bond_vocab.pkl', cuda=True, data_path='exampledata/pretrain/tryout', dense=False, depth=5, dist_coff=0.1, dropout=0.1, embedding_output_type='both', enable_multi_gpu=False, epochs=3, fg_label_path=None, final_lr=0.0001, fine_tune_coff=1, hidden_size=100, init_lr=0.0002, max_lr=0.0004, no_cache=True, num_attn_head=1, num_mt_block=1, parser_name='pretrain', save_dir='model/tryout', save_interval=9999999999, undirected=False, warmup_epochs=2.0, weight_decay=1e-07)\n",
            "Loading data\n",
            "Loading data:\n",
            "Number of files: 60\n",
            "Number of samples: 5970\n",
            "Samples/file: 100\n",
            "Splitting data with seed 0.\n",
            "Total size = 5,970 | train size = 5,400 | val size = 570\n",
            "atom vocab size: 324, bond vocab size: 353, Number of FG tasks: 85\n",
            "Pre-loaded test data: 6\n",
            "No checkpoint found %d\n",
            "GROVEREmbedding(\n",
            "  (encoders): GTransEncoder(\n",
            "    (edge_blocks): ModuleList(\n",
            "      (0): MTBlock(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (mpn_q): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_k): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_v): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (act_func): PReLU(num_parameters=1)\n",
            "        (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "        (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "        (W_i): Linear(in_features=165, out_features=100, bias=False)\n",
            "        (attn): MultiHeadedAttention(\n",
            "          (linear_layers): ModuleList(\n",
            "            (0-2): 3 x Linear(in_features=100, out_features=100, bias=True)\n",
            "          )\n",
            "          (output_linear): Linear(in_features=100, out_features=100, bias=False)\n",
            "          (attention): Attention()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
            "        (sublayer): SublayerConnection(\n",
            "          (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (node_blocks): ModuleList(\n",
            "      (0): MTBlock(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (mpn_q): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_k): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_v): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (act_func): PReLU(num_parameters=1)\n",
            "        (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "        (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "        (W_i): Linear(in_features=151, out_features=100, bias=False)\n",
            "        (attn): MultiHeadedAttention(\n",
            "          (linear_layers): ModuleList(\n",
            "            (0-2): 3 x Linear(in_features=100, out_features=100, bias=True)\n",
            "          )\n",
            "          (output_linear): Linear(in_features=100, out_features=100, bias=False)\n",
            "          (attention): Attention()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
            "        (sublayer): SublayerConnection(\n",
            "          (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ffn_atom_from_atom): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=251, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ffn_atom_from_bond): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=251, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ffn_bond_from_atom): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=265, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ffn_bond_from_bond): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=265, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (atom_from_atom_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (atom_from_bond_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (bond_from_atom_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (bond_from_bond_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (act_func_node): PReLU(num_parameters=1)\n",
            "    (act_func_edge): PReLU(num_parameters=1)\n",
            "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Total parameters: 768614\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "Epoch: 0001 loss_train: 14.196014 loss_val: 7.871470 loss_val_av: 3.137376 loss_val_bv: 3.529978 loss_val_fg: 1.204115 cur_lr: 0.00030 t_time: 11.3616s v_time: 1.3510s d_time: 0.0000s\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "Epoch: 0002 loss_train: 6.847821 loss_val: 4.170161 loss_val_av: 1.377140 loss_val_bv: 1.837263 loss_val_fg: 0.955758 cur_lr: 0.00039 t_time: 11.2998s v_time: 1.0821s d_time: 0.0000s\n",
            "EP:3 Model Saved on: model/tryout/model.ep3\n",
            "Total Time: 26.067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Molecular Feature Extraction"
      ],
      "metadata": {
        "id": "nXtM2I2sjlN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/save_features.py --data_path ../drive/MyDrive/Thesis/Data/HTSFP_smiles.csv \\\n",
        "                                --save_path ../drive/MyDrive/Thesis/Data/HTSFP_smiles.npz \\\n",
        "                                --features_generator rdkit_2d_normalized \\\n",
        "                                --restart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmiQ75WpjlXs",
        "outputId": "9fa025d7-4270-4df5-c193-ea94fd420e66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:57:04] WARNING: not removing hydrogen atom without neighbors\n",
            "[10:57:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[10:57:59] WARNING: not removing hydrogen atom without neighbors\n",
            "  8% 27719/364290 [03:51<51:49, 108.24it/s][11:01:52] WARNING: not removing hydrogen atom without neighbors\n",
            "  8% 27732/364290 [03:51<55:11, 101.65it/s][11:01:52] WARNING: not removing hydrogen atom without neighbors\n",
            " 97% 351770/364290 [48:29<01:31, 136.20it/s][11:46:31] WARNING: not removing hydrogen atom without neighbors\n",
            " 97% 351799/364290 [48:29<01:36, 129.85it/s][11:46:31] WARNING: not removing hydrogen atom without neighbors\n",
            " 98% 357733/364290 [49:18<00:51, 128.06it/s][11:47:20] WARNING: not removing hydrogen atom without neighbors\n",
            " 98% 357747/364290 [49:19<00:55, 117.41it/s][11:47:20] WARNING: not removing hydrogen atom without neighbors\n",
            "100% 364290/364290 [50:13<00:00, 120.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Fingerprints"
      ],
      "metadata": {
        "id": "Saub3MftmZrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py fingerprint --data_path ../drive/MyDrive/Thesis/Data/HTSFP_smiles.csv \\\n",
        "                           --features_path ../drive/MyDrive/Thesis/Data/HTSFP_smiles.npz \\\n",
        "                           --checkpoint_path ../drive/MyDrive/Thesis/Model/grover_large.pt \\\n",
        "                           --fingerprint_source both \\\n",
        "                           --output ../drive/MyDrive/Thesis/Data/fp_large.npz"
      ],
      "metadata": {
        "id": "DuCb2t3VjyPV",
        "outputId": "4f9e19d2-8ab6-4858-e201-37367b37c9fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\n",
            "Loading data\n",
            "Total size = 364,290\n",
            "Generating...\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
            "Moving model to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Fingerprints"
      ],
      "metadata": {
        "id": "gm0LmXiVn3t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect current working directory\n",
        "%pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PmveN4N7oI-k",
        "outputId": "72ce9705-bef7-41f5-dd9b-51a79638e25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/grover/grover'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "file_path = '../drive/MyDrive/Thesis/Data/fp_large.npz'\n",
        "data = np.load(file_path, allow_pickle=True)\n",
        "print(data.keys())  # Display the keys or attributes in the file\n",
        "# Access and examine the data as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF-vpBy6n32h",
        "outputId": "5726887b-45c2-4d81-a9b9-9da9f82ad5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['smiles', 'fps'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['smiles']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Qc84MfpeAv",
        "outputId": "2cf46893-4e4f-4411-c146-701f1dee69ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        [Cl].CC(C)NCC(O)COc1cccc2ccccc12\n",
              "1                C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl\n",
              "2       c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...\n",
              "3                        C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C\n",
              "4       Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...\n",
              "                              ...                        \n",
              "2034      C1=C(Cl)C(=C(C2=C1NC(=O)C(N2)=O)[N+](=O)[O-])Cl\n",
              "2035    [C@H]3([N]2C1=C(C(=NC=N1)N)N=C2)[C@@H]([C@@H](...\n",
              "2036    [O+]1=N[N](C=C1[N-]C(NC2=CC=CC=C2)=O)C(CC3=CC=...\n",
              "2037    C1=C(OC)C(=CC2=C1C(=[N+](C(=C2CC)C)[NH-])C3=CC...\n",
              "2038    [N+](=NCC(=O)N[C@@H]([C@H](O)C1=CC=C([N+]([O-]...\n",
              "Name: smiles, Length: 2039, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['fps'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt89Qb0Opmyx",
        "outputId": "754c2f44-21dc-45c6-a2ef-560015169cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-7.89292872e-01,  6.27004743e-01, -7.91928768e-01,  8.19022357e-01,\n",
              "        1.20746446e+00, -6.24105275e-01, -3.46923053e-01,  8.49374890e-01,\n",
              "        8.20919037e-01, -1.54049575e-01,  8.29877853e-01,  4.32644606e-01,\n",
              "        5.30687988e-01,  3.36008608e-01, -7.81888783e-01,  2.69850731e-01,\n",
              "        6.18666649e-01,  4.25872773e-01,  5.46775401e-01,  2.79903322e-01,\n",
              "       -8.91439080e-01, -9.49716289e-03, -1.70764938e-01, -2.51722157e-01,\n",
              "       -6.84444308e-01,  9.06562984e-01, -2.95437515e-01,  4.21518534e-02,\n",
              "        4.10546929e-01, -7.60677934e-01, -7.80300856e-01,  7.80405283e-01,\n",
              "       -9.63750303e-01,  5.04185930e-02,  1.18975961e+00,  5.15425801e-01,\n",
              "       -2.83948660e-01, -9.82012689e-01, -2.98990875e-01,  4.26783040e-02,\n",
              "       -9.33582306e-01, -6.60347641e-01, -7.30285347e-01, -7.36297131e-01,\n",
              "       -8.12867165e-01,  2.50640601e-01,  3.30958143e-02, -5.80460727e-01,\n",
              "       -5.62716782e-01,  5.79053521e-01,  7.84362674e-01, -4.43908900e-01,\n",
              "        6.40295148e-01,  6.09267175e-01,  3.53539050e-01, -8.25176418e-01,\n",
              "       -1.01936173e+00,  1.70370564e-01,  5.90038419e-01, -9.89060402e-01,\n",
              "        8.13774109e-01,  3.89836401e-01, -4.78592128e-01,  5.20094812e-01,\n",
              "       -8.30688953e-01,  8.42934132e-01,  8.64690423e-01,  6.80442452e-01,\n",
              "        6.02820039e-01,  4.25647665e-03, -9.38837171e-01, -1.36332512e-01,\n",
              "        6.55890048e-01,  9.88287151e-01,  8.95878255e-01,  7.12538123e-01,\n",
              "       -1.09892762e+00,  5.66313088e-01, -9.74002063e-01, -5.85918725e-01,\n",
              "       -1.31455794e-01, -5.29134333e-01, -1.09108257e+00, -7.49993801e-01,\n",
              "       -2.64782429e-01,  1.01291776e+00,  1.11097491e+00, -7.29593575e-01,\n",
              "        8.29851925e-01,  3.76613915e-01,  1.11196125e+00,  9.28918779e-01,\n",
              "       -1.34230781e+00, -8.25209320e-01,  2.67516255e-01, -1.84003711e-01,\n",
              "        6.83035374e-01, -8.32260549e-01, -7.98111379e-01, -9.21037138e-01,\n",
              "       -5.49227417e-01, -3.87995899e-01,  1.90254077e-01,  1.93708301e-01,\n",
              "        8.11076581e-01, -7.59598255e-01, -8.33152950e-01, -4.76480305e-01,\n",
              "        6.91054463e-02, -5.77809751e-01,  8.63418221e-01,  4.02918071e-01,\n",
              "       -8.71556103e-01, -9.07467306e-01, -6.16045773e-01,  2.60324210e-01,\n",
              "        7.46195912e-01, -6.20374203e-01, -4.17672247e-01,  3.80941242e-01,\n",
              "       -5.13017416e-01, -4.74504381e-01, -1.04015243e+00, -8.34035575e-01,\n",
              "       -1.09075105e+00, -5.28190613e-01, -7.42559314e-01, -7.58582830e-01,\n",
              "        6.58231437e-01, -3.47643763e-01, -7.63485730e-01,  7.42834270e-01,\n",
              "       -3.06419522e-01,  4.06932563e-01, -6.02950692e-01,  6.70587644e-02,\n",
              "       -4.21677738e-01, -1.86553955e-01,  8.62533033e-01,  1.08807254e+00,\n",
              "        7.86793351e-01,  9.93768394e-01,  8.47102940e-01,  5.42005837e-01,\n",
              "       -2.57974923e-01, -2.84801930e-01, -8.99963677e-01, -7.45623410e-01,\n",
              "       -6.82408035e-01,  4.60331202e-01,  4.09332523e-03,  9.64273155e-01,\n",
              "       -9.70841408e-01,  1.40995908e+00,  9.67498124e-01, -1.16450536e+00,\n",
              "       -1.83561370e-01, -4.28680420e-01,  5.76689124e-01,  5.45831978e-01,\n",
              "        4.40412432e-01,  8.80142629e-01, -4.49211925e-01, -2.23208576e-01,\n",
              "        3.74061912e-01, -1.09040248e+00, -7.17695177e-01,  8.05142701e-01,\n",
              "        4.96431321e-01, -8.16835344e-01,  2.12201506e-01,  3.47760648e-01,\n",
              "        8.61930788e-01,  3.56836729e-02, -3.95608991e-01,  7.96224117e-01,\n",
              "        2.90590107e-01, -5.08603573e-01,  7.83870339e-01,  1.32663712e-01,\n",
              "        1.65740415e-01, -7.37913132e-01,  7.63222694e-01,  8.25147092e-01,\n",
              "        6.84470952e-01, -2.60484755e-01,  9.06798005e-01, -1.02454662e+00,\n",
              "        7.09189415e-01, -3.39642279e-02, -1.31178224e+00,  5.75410306e-01,\n",
              "       -8.23495805e-01, -1.12630880e+00,  1.05910766e+00,  1.09357786e+00,\n",
              "        8.14246118e-01, -8.00102413e-01,  5.89084387e-01,  7.33778536e-01,\n",
              "        3.90776128e-01, -8.53640378e-01,  3.69128883e-01,  1.08256519e+00,\n",
              "        4.57358897e-01,  5.02652586e-01,  6.46554947e-01,  6.07077539e-01,\n",
              "       -5.05878218e-02,  4.09405529e-01, -1.10960197e+00, -4.58466977e-01,\n",
              "       -1.53377533e-01, -3.68790597e-01, -4.84656185e-01, -6.93117142e-01,\n",
              "        1.94436908e-01, -4.10850346e-01,  1.05682397e+00, -4.36738491e-01,\n",
              "        3.69948119e-01, -5.96931279e-01,  5.12586534e-01, -6.61236882e-01,\n",
              "       -1.07768500e+00, -5.34021199e-01,  1.10589780e-01, -2.73138911e-01,\n",
              "        7.04796851e-01, -8.60049725e-01,  4.89124030e-01,  5.71507275e-01,\n",
              "        8.05455327e-01,  8.17423761e-01,  3.76526654e-01,  5.70122182e-01,\n",
              "        1.22478807e+00,  8.06515396e-01,  5.58147907e-01,  1.05605745e+00,\n",
              "        8.64132345e-01,  3.50251824e-01, -4.25615370e-01, -5.12242496e-01,\n",
              "        9.76473033e-01,  3.95293325e-01,  6.88971639e-01, -7.65239894e-01,\n",
              "        2.28770807e-01, -1.50419429e-01, -5.11549890e-01,  6.09214783e-01,\n",
              "       -1.90916210e-02,  5.75046241e-01, -3.25507611e-01, -5.46592176e-01,\n",
              "       -4.42249596e-01,  1.18468873e-01,  9.56674516e-01, -6.24543786e-01,\n",
              "       -1.31454563e+00,  9.32352483e-01,  2.01566607e-01, -4.13119406e-01,\n",
              "       -3.02175581e-01, -1.08459747e+00, -6.02454066e-01, -8.82627308e-01,\n",
              "       -1.52580783e-01, -8.01942825e-01, -2.82145590e-01,  3.32148939e-01,\n",
              "       -8.13731372e-01,  2.85260767e-01,  6.05487525e-01, -6.32073998e-01,\n",
              "        6.85528934e-01,  2.81035453e-01, -7.29792953e-01, -6.54860377e-01,\n",
              "        9.43124294e-01,  7.34097064e-01,  8.49223912e-01,  3.75893921e-01,\n",
              "       -5.49502850e-01,  3.82402539e-01, -9.05456960e-01, -1.03402066e+00,\n",
              "       -7.84267008e-01, -5.10300934e-01,  3.81747693e-01, -1.05598772e+00,\n",
              "        9.70460415e-01, -1.06613696e-01,  2.52404332e-01,  7.10138500e-01,\n",
              "       -2.15037376e-01,  1.51259348e-01, -6.64014161e-01, -1.33011520e+00,\n",
              "       -8.92721653e-01, -8.85272980e-01, -5.37119687e-01,  6.28729761e-01,\n",
              "       -7.85623610e-01, -2.02061579e-01,  8.83942127e-01, -7.79425144e-01,\n",
              "        9.81220663e-01, -5.96472681e-01,  6.15981579e-01, -1.33354080e+00,\n",
              "        6.50141835e-01, -4.36933100e-01,  3.23466927e-01, -4.49645013e-01,\n",
              "        3.86507750e-01,  4.62588996e-01, -6.90142810e-01, -9.36101437e-01,\n",
              "       -9.66111600e-01,  1.76955342e-01, -5.16034007e-01,  5.39243758e-01,\n",
              "       -6.18624508e-01,  4.29617256e-01,  1.05038345e+00,  4.23175156e-01,\n",
              "       -1.91498920e-01,  2.93238789e-01,  5.94043672e-01,  2.67622739e-01,\n",
              "        3.73202354e-01,  7.47645020e-01, -4.37063694e-01,  6.36118233e-01,\n",
              "        1.08607805e+00,  9.60735008e-02, -3.81882012e-01, -9.27920118e-02,\n",
              "        6.17820859e-01,  1.28330076e+00,  1.82400987e-01,  4.37673956e-01,\n",
              "       -1.17320490e+00,  8.68840739e-02,  5.31407058e-01, -4.77176249e-01,\n",
              "        4.24347967e-01,  6.36791959e-02,  7.84949243e-01, -3.08462065e-02,\n",
              "        5.36161721e-01,  5.77724159e-01, -9.22201276e-01,  1.24862421e+00,\n",
              "       -1.84822544e-01,  3.60486746e-01, -5.83231807e-01,  2.48504043e-01,\n",
              "       -3.41626137e-01,  1.02210796e+00,  5.29371023e-01, -2.04960808e-01,\n",
              "       -8.71386349e-01,  8.10082853e-01, -7.78127074e-01, -6.36644244e-01,\n",
              "       -1.30807257e+00, -5.64692318e-01, -1.04077721e+00, -3.30281645e-01,\n",
              "        6.87083676e-02,  2.72849560e-01, -4.19279158e-01, -2.92055488e-01,\n",
              "        8.62063348e-01,  1.16372001e+00, -4.23962086e-01,  3.10924381e-01,\n",
              "        1.67223915e-01,  1.33485049e-01,  5.13256252e-01, -7.46401429e-01,\n",
              "        4.63318020e-01,  7.54587054e-01, -4.50622857e-01, -2.31136754e-01,\n",
              "       -7.74131000e-01, -7.83958614e-01,  1.32950783e-01, -8.83010507e-01,\n",
              "       -7.53608882e-01, -6.52010858e-01, -5.86712539e-01,  9.81840730e-01,\n",
              "       -2.82910820e-02,  1.52119875e+00,  3.51683378e-01, -5.47567546e-01,\n",
              "        1.96076362e-05,  1.11832820e-01,  1.06450796e-01,  1.77349940e-01,\n",
              "        1.87814608e-01,  1.10053547e-01,  1.68671876e-01,  1.19390793e-01,\n",
              "        1.85865715e-01,  1.19536787e-01,  1.19686596e-01,  7.26963431e-02,\n",
              "        1.26147002e-01,  7.79882073e-02,  6.10115886e-01,  2.82315880e-01,\n",
              "        6.89356852e-07,  4.40791845e-01,  5.46155453e-01,  4.19837415e-01,\n",
              "        9.25841695e-11,  5.85610919e-17,  6.51996613e-01,  7.78625727e-01,\n",
              "        3.49110782e-01,  1.55699387e-01,  5.06393731e-01,  4.40084130e-01,\n",
              "        5.50254464e-01,  5.28931916e-01,  9.12710547e-01,  1.37062073e-01,\n",
              "        1.46173328e-01,  9.99998987e-01,  3.33629578e-01,  5.03374219e-01,\n",
              "        5.81981719e-01,  1.75720215e-01,  5.30076101e-02,  8.19622815e-01,\n",
              "        5.30076101e-02,  5.68835549e-02,  3.24286625e-10,  4.40142676e-02,\n",
              "        4.33838934e-01,  1.69037938e-01,  4.63312745e-01,  2.10664883e-01,\n",
              "        1.52884930e-01,  7.07278669e-01,  1.24047369e-01,  9.93858718e-22,\n",
              "        1.42492250e-01,  6.29631355e-02,  6.35287762e-01,  4.82993010e-15,\n",
              "        3.85834038e-01,  1.68438017e-01,  7.31660187e-01,  9.82373953e-02,\n",
              "        1.00000000e+00,  4.66310263e-01,  0.00000000e+00,  1.14242660e-21,\n",
              "        2.40245506e-23,  1.77145794e-01,  6.12260163e-01,  8.69873345e-01,\n",
              "        3.60875253e-15,  1.45980120e-01,  1.73556720e-22,  1.18093646e-10,\n",
              "        5.99833801e-02,  9.05498609e-08,  4.60978367e-10,  1.57072380e-01,\n",
              "        7.89781868e-01,  6.44137561e-02,  7.28170276e-01,  2.75008846e-02,\n",
              "        1.20265670e-01,  3.24090809e-01,  5.71146190e-01,  1.67096868e-01,\n",
              "        2.05072373e-01,  8.78622232e-24,  5.31226337e-01,  4.50414181e-01,\n",
              "        2.92070925e-01,  5.30138095e-05,  6.99547827e-01,  6.03355110e-01,\n",
              "        6.95272019e-13,  7.09806383e-01,  9.86699045e-01,  4.00590718e-01,\n",
              "        1.20493060e-11,  2.86305002e-09,  2.37261027e-01,  4.66589361e-01,\n",
              "        2.99487760e-06,  9.85541642e-01,  5.30138095e-05,  1.02915592e-01,\n",
              "        5.30138095e-05,  5.00000000e-01,  3.84710461e-01,  5.30138095e-05,\n",
              "        5.30138095e-05,  9.99817133e-01,  5.30138095e-05,  0.00000000e+00,\n",
              "        9.02640224e-01,  2.02868339e-02,  5.70867843e-19,  9.99247134e-01,\n",
              "        9.97862101e-01,  7.10542736e-15,  5.83707561e-13,  1.19880645e-20,\n",
              "        1.65079549e-01,  1.67040631e-01,  1.66498333e-01,  1.66486815e-01,\n",
              "        2.02864662e-01,  6.93658814e-02,  7.10542736e-15,  1.68346480e-01,\n",
              "        1.67982936e-01,  6.87189861e-10,  5.98257124e-01,  1.64332628e-01,\n",
              "        8.37776926e-04,  1.66325733e-01,  1.63034141e-01,  1.65079549e-01,\n",
              "        9.56970467e-08,  3.49708920e-08,  1.68206170e-01,  1.65806860e-01,\n",
              "        1.67346597e-01,  7.13964596e-07,  2.64115097e-12,  9.99127924e-02,\n",
              "        2.86809132e-10,  3.77737850e-01,  4.50616796e-03,  1.33250251e-01,\n",
              "        6.35349631e-01,  1.61482916e-09,  9.14027333e-01,  2.09410544e-07,\n",
              "        7.10542736e-15,  4.99264270e-01,  1.64929405e-01,  7.60844767e-01,\n",
              "        2.11164361e-16,  1.16815879e-09,  9.09514666e-01,  6.24601426e-10,\n",
              "        1.68149188e-01,  1.65450722e-01,  1.17110260e-13,  0.00000000e+00,\n",
              "        1.64668873e-01,  1.66924730e-01,  0.00000000e+00,  5.10071345e-08,\n",
              "        7.10542736e-15,  1.54654115e-01,  2.79420944e-22,  0.00000000e+00,\n",
              "        1.67639732e-01,  6.31499277e-25,  1.68186128e-01,  9.08850227e-03,\n",
              "        1.68363199e-01,  8.26542307e-11,  1.56346351e-01,  0.00000000e+00,\n",
              "        0.00000000e+00,  2.11354233e-02,  2.11354233e-02,  2.38815573e-20,\n",
              "        0.00000000e+00,  8.33672445e-25,  5.30138095e-05,  1.56951070e-01,\n",
              "        4.03434512e-08,  1.55259202e-23,  1.59306119e-17,  5.76610089e-14,\n",
              "        2.95798941e-11,  1.68378368e-01,  1.67380184e-01,  1.48151460e-18,\n",
              "        2.32414988e-16,  4.70359822e-08,  1.66633397e-01,  9.30688262e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "9I3W92KKGmPX"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}