{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidkubanek/Thesis/blob/main/grover_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NATXVd23fu7Z"
      },
      "source": [
        "# GROVER\n",
        "### Generate graph transformer molecular fingerprints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCsRgDsSfv_n"
      },
      "source": [
        "Change version of python to more closely match the desired GROVER environment. I ran this on google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWMcIrsaNwqz",
        "outputId": "b15dcfa8-abe0-4499-e120-d58ce26096f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "update-alternatives: --install needs <link> <name> <path> <priority>\n",
            "\n",
            "Use 'update-alternatives --help' for program usage information.\n",
            "update-alternatives: error: no alternatives for python3\n",
            "Python version:\n",
            "Python 3.10.12\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,965 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.3 [1,305 kB]\n",
            "Fetched 1,677 kB in 1s (1,176 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 121151 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "#*Add python version you wish* to list\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8\n",
        "\n",
        "# Choose one of the given alternatives:\n",
        "#!sudo update-alternatives --config python3\n",
        "# OR\n",
        "!update-alternatives --set python3 /usr/bin/python3.8\n",
        "\n",
        "# Check the result\n",
        "print('Python version:')\n",
        "!python3 --version\n",
        "\n",
        "# Attention: Install pip (... needed!)\n",
        "!sudo apt install python3-pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xiwel4iegSlV"
      },
      "source": [
        "Download relevant packages with compatible versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y--0itscQW0J",
        "outputId": "37831661-d843-4ab4-c1fd-dc168ded8000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.24.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.12.2)\n",
            "Requirement already satisfied: platformdirs<4,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.9.1)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.7 virtualenv-20.24.2\n",
            "created virtual environment CPython3.10.12.final.0-64 in 547ms\n",
            "  creator CPython3Posix(dest=/content/grover_env, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==23.2.1, setuptools==68.0.0, wheel==0.41.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv grover_env\n",
        "!source grover_env/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "52nyiMs8QfVd",
        "outputId": "96e2125b-a3a0-403e-e23b-e3d1318215df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting boost\n",
            "  Downloading boost-0.1.tar.gz (6.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Mastodon.py (from boost)\n",
            "  Downloading Mastodon.py-1.8.1-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from boost) (2.0.19)\n",
            "Requirement already satisfied: requests>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from Mastodon.py->boost) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from Mastodon.py->boost) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Mastodon.py->boost) (1.16.0)\n",
            "Requirement already satisfied: decorator>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from Mastodon.py->boost) (4.4.2)\n",
            "Collecting blurhash>=1.1.4 (from Mastodon.py->boost)\n",
            "  Downloading blurhash-1.1.4-py2.py3-none-any.whl (5.3 kB)\n",
            "Collecting python-magic (from Mastodon.py->boost)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->boost) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->boost) (2.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->Mastodon.py->boost) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->Mastodon.py->boost) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->Mastodon.py->boost) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->Mastodon.py->boost) (3.4)\n",
            "Building wheels for collected packages: boost\n",
            "  Building wheel for boost (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boost: filename=boost-0.1-py3-none-any.whl size=12445 sha256=c4622d473b2ddf2faa34c9408caf444b09dd1eaf020b7f2c6d90279f73789952\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/87/ab/8641d30039f2fb7605bab327a7e0608359c304ce565a1e6614\n",
            "Successfully built boost\n",
            "Installing collected packages: blurhash, python-magic, Mastodon.py, boost\n",
            "Successfully installed Mastodon.py-1.8.1 blurhash-1.1.4 boost-0.1 python-magic-0.4.27\n",
            "Collecting descriptastorus\n",
            "  Downloading descriptastorus-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas-flavor (from descriptastorus)\n",
            "  Downloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting rdkit (from descriptastorus)\n",
            "  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from descriptastorus) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from descriptastorus) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.10/dist-packages (from pandas-flavor->descriptastorus) (1.5.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor->descriptastorus) (2022.12.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->descriptastorus) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-flavor->descriptastorus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-flavor->descriptastorus) (2022.7.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray->pandas-flavor->descriptastorus) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas-flavor->descriptastorus) (1.16.0)\n",
            "Installing collected packages: rdkit, pandas-flavor, descriptastorus\n",
            "Successfully installed descriptastorus-2.6.1 pandas-flavor-0.6.0 rdkit-2023.3.2\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Collecting readline\n",
            "  Downloading readline-6.2.4.1.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: readline\n",
            "  Building wheel for readline (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for readline: filename=readline-6.2.4.1-cp310-cp310-linux_x86_64.whl size=352168 sha256=dca145a2beb8772dc7fbabae3cbab33261f61f7b7be7e3d709deaa580bd307bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/72/7b/8fd414ffab7293e57db7952795d7ab13baffe0b5e444483bca\n",
            "Successfully built readline\n",
            "Installing collected packages: readline\n",
            "Successfully installed readline-6.2.4.1\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Collecting scipy==1.5.2\n",
            "  Downloading scipy-1.5.2.tar.gz (25.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.4/25.4 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting tqdm==4.32.1\n",
            "  Downloading tqdm-4.32.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 1.2.1 requires tqdm>=4.48.0, but you have tqdm 4.32.1 which is incompatible.\n",
            "prophet 1.1.4 requires tqdm>=4.36.1, but you have tqdm 4.32.1 which is incompatible.\n",
            "spacy 3.5.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.32.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.32.1\n",
            "Collecting typing==3.6.4\n",
            "  Downloading typing-3.6.4-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: typing\n",
            "Successfully installed typing-3.6.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install boost\n",
        "!pip install descriptastorus\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install tensorboard\n",
        "!pip install torchvision\n",
        "!pip install rdkit\n",
        "!pip install readline\n",
        "!pip install scikit-learn\n",
        "!pip install scipy==1.5.2\n",
        "!pip install tqdm==4.32.1\n",
        "!pip install typing==3.6.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwgEATOeWHr9"
      },
      "source": [
        "# Run GROVER repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrh_te0zN0pa",
        "outputId": "6d2027b3-d4d8-49ea-cbfb-fe89d4bde19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'grover'...\n",
            "remote: Enumerating objects: 278, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (175/175), done.\u001b[K\n",
            "remote: Total 278 (delta 31), reused 168 (delta 19), pack-reused 82\u001b[K\n",
            "Receiving objects: 100% (278/278), 17.68 MiB | 18.11 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/davidkubanek/grover.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-H-grAnfsTW"
      },
      "source": [
        "### Navigate to the correct directory for running the scripts below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elYMcsEhZd1f",
        "outputId": "e1f3bcdc-d6f5-4a1a-99a2-85da9f7da273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b41zhgB6fAef",
        "outputId": "b2fc6ebf-6abc-46fc-8042-b0b77b6f49c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/grover\n"
          ]
        }
      ],
      "source": [
        "%cd grover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "miqk2jCSiPWe"
      },
      "outputs": [],
      "source": [
        "# Unmount Google Drive\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re8a3FrJg8ZJ",
        "outputId": "957fa79c-160a-46ac-860a-df49fa1674c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol_ZMUAGiC_z",
        "outputId": "3c4d21c8-c01b-479d-d8cf-f1ee4b0d5ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mgrover\u001b[0m/  \u001b[01;34mgrover_env\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTpXB6eKiklD",
        "outputId": "0a6c7335-bf86-4c5e-cc05-960bc1608174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2wIqutpjilC"
      },
      "source": [
        "### Pre-training\n",
        "Not necessary if using a pre-trained model grover_base.pt/grover_large.pt checkpoint. If running pre-training from scratch, the motif and atom/bond feature extraction steps prior to pre-training would also have to be run. The present pre-training works for the tryout.csv data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsqzEKeeWKT6",
        "outputId": "010ee062-f663-463d-8190-5a9025af99f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\n",
            "Namespace(activation='PReLU', atom_vocab_path='exampledata/pretrain/tryout_atom_vocab.pkl', backbone='gtrans', batch_size=32, bias=False, bond_drop_rate=0, bond_vocab_path='exampledata/pretrain/tryout_bond_vocab.pkl', cuda=True, data_path='exampledata/pretrain/tryout', dense=False, depth=5, dist_coff=0.1, dropout=0.1, embedding_output_type='both', enable_multi_gpu=False, epochs=3, fg_label_path=None, final_lr=0.0001, fine_tune_coff=1, hidden_size=100, init_lr=0.0002, max_lr=0.0004, no_cache=True, num_attn_head=1, num_mt_block=1, parser_name='pretrain', save_dir='model/tryout', save_interval=9999999999, undirected=False, warmup_epochs=2.0, weight_decay=1e-07)\n",
            "Loading data\n",
            "Loading data:\n",
            "Number of files: 60\n",
            "Number of samples: 5970\n",
            "Samples/file: 100\n",
            "Splitting data with seed 0.\n",
            "Total size = 5,970 | train size = 5,400 | val size = 570\n",
            "atom vocab size: 324, bond vocab size: 353, Number of FG tasks: 85\n",
            "Pre-loaded test data: 6\n",
            "No checkpoint found %d\n",
            "GROVEREmbedding(\n",
            "  (encoders): GTransEncoder(\n",
            "    (edge_blocks): ModuleList(\n",
            "      (0): MTBlock(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (mpn_q): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_k): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_v): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (act_func): PReLU(num_parameters=1)\n",
            "        (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "        (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "        (W_i): Linear(in_features=165, out_features=100, bias=False)\n",
            "        (attn): MultiHeadedAttention(\n",
            "          (linear_layers): ModuleList(\n",
            "            (0-2): 3 x Linear(in_features=100, out_features=100, bias=True)\n",
            "          )\n",
            "          (output_linear): Linear(in_features=100, out_features=100, bias=False)\n",
            "          (attention): Attention()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
            "        (sublayer): SublayerConnection(\n",
            "          (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (node_blocks): ModuleList(\n",
            "      (0): MTBlock(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (mpn_q): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_k): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "            (mpn_v): MPNEncoder(\n",
            "              (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "              (act_func): PReLU(num_parameters=1)\n",
            "              (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (act_func): PReLU(num_parameters=1)\n",
            "        (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "        (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "        (W_i): Linear(in_features=151, out_features=100, bias=False)\n",
            "        (attn): MultiHeadedAttention(\n",
            "          (linear_layers): ModuleList(\n",
            "            (0-2): 3 x Linear(in_features=100, out_features=100, bias=True)\n",
            "          )\n",
            "          (output_linear): Linear(in_features=100, out_features=100, bias=False)\n",
            "          (attention): Attention()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
            "        (sublayer): SublayerConnection(\n",
            "          (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ffn_atom_from_atom): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=251, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ffn_atom_from_bond): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=251, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ffn_bond_from_atom): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=265, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ffn_bond_from_bond): PositionwiseFeedForward(\n",
            "      (W_1): Linear(in_features=265, out_features=400, bias=True)\n",
            "      (W_2): Linear(in_features=400, out_features=100, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (act_func): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (atom_from_atom_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (atom_from_bond_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (bond_from_atom_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (bond_from_bond_sublayer): SublayerConnection(\n",
            "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (act_func_node): PReLU(num_parameters=1)\n",
            "    (act_func_edge): PReLU(num_parameters=1)\n",
            "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n",
            "Total parameters: 768614\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "Epoch: 0001 loss_train: 14.196014 loss_val: 7.871470 loss_val_av: 3.137376 loss_val_bv: 3.529978 loss_val_fg: 1.204115 cur_lr: 0.00030 t_time: 11.3616s v_time: 1.3510s d_time: 0.0000s\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "/content/grover/grover/data/groverdataset.py:240: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  fgroup_label = torch.Tensor([d.features for d in batch]).float()\n",
            "Epoch: 0002 loss_train: 6.847821 loss_val: 4.170161 loss_val_av: 1.377140 loss_val_bv: 1.837263 loss_val_fg: 0.955758 cur_lr: 0.00039 t_time: 11.2998s v_time: 1.0821s d_time: 0.0000s\n",
            "EP:3 Model Saved on: model/tryout/model.ep3\n",
            "Total Time: 26.067\n"
          ]
        }
      ],
      "source": [
        "!python main.py pretrain \\\n",
        "               --data_path exampledata/pretrain/tryout \\\n",
        "               --save_dir model/tryout \\\n",
        "               --atom_vocab_path exampledata/pretrain/tryout_atom_vocab.pkl \\\n",
        "               --bond_vocab_path exampledata/pretrain/tryout_bond_vocab.pkl \\\n",
        "               --batch_size 32 \\\n",
        "               --dropout 0.1 \\\n",
        "               --depth 5 \\\n",
        "               --num_attn_head 1 \\\n",
        "               --hidden_size 100 \\\n",
        "               --epochs 3 \\\n",
        "               --init_lr 0.0002 \\\n",
        "               --max_lr 0.0004 \\\n",
        "               --final_lr 0.0001 \\\n",
        "               --weight_decay 0.0000001 \\\n",
        "               --activation PReLU \\\n",
        "               --backbone gtrans \\\n",
        "               --embedding_output_type both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXtM2I2sjlN0"
      },
      "source": [
        "### Molecular Feature Extraction\n",
        "Needs a 'smiles.csv' file of the compounds that we wish to generate fingerprints for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmiQ75WpjlXs",
        "outputId": "cf13451e-2ec7-4b50-f5f0-6daa28d43071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15:26:20] WARNING: not removing hydrogen atom without neighbors\n",
            "[15:26:20] WARNING: not removing hydrogen atom without neighbors\n",
            " 43% 140593/324192 [59:03<1:20:22, 38.07it/s][16:25:53] WARNING: not removing hydrogen atom without neighbors\n",
            " 43% 140622/324192 [59:03<1:15:54, 40.31it/s][16:25:54] WARNING: not removing hydrogen atom without neighbors\n",
            " 43% 140818/324192 [59:07<1:05:19, 46.79it/s][16:25:58] WARNING: not removing hydrogen atom without neighbors\n",
            " 43% 140844/324192 [59:08<1:05:32, 46.62it/s][16:25:59] WARNING: not removing hydrogen atom without neighbors\n",
            "100% 324192/324192 [2:16:18<00:00, 39.64it/s]\n"
          ]
        }
      ],
      "source": [
        "!python scripts/save_features.py --data_path ../drive/MyDrive/Thesis/Data/smiles_filtered_579_median.csv \\\n",
        "                                --save_path ../drive/MyDrive/Thesis/Data/HTSFP_smiles.npz \\\n",
        "                                --features_generator rdkit_2d_normalized \\\n",
        "                                --restart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Saub3MftmZrw"
      },
      "source": [
        "### Generating Fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuCb2t3VjyPV",
        "outputId": "efcc96e1-a0ec-424f-84dd-f821bfe7f335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\n",
            "Loading data\n",
            "Total size = 324,192\n",
            "Generating...\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.layernorm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_i.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.0.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.linear_layers.2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.attn.output_linear.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.W_o.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.edge_blocks.0.sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.1.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.2.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_q.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_k.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.heads.3.mpn_v.W_h.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.layernorm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_i.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.0.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.linear_layers.2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.attn.output_linear.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.W_o.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.node_blocks.0.sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_atom.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_atom_from_bond.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_atom.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_1.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.W_2.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.ffn_bond_from_bond.act_func.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_atom_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.atom_from_bond_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_atom_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.bond_from_bond_sublayer.norm.bias\".\n",
            "Loading pretrained parameter \"grover.encoders.act_func_node.weight\".\n",
            "Loading pretrained parameter \"grover.encoders.act_func_edge.weight\".\n",
            "Moving model to cuda\n"
          ]
        }
      ],
      "source": [
        "!python main.py fingerprint --data_path ../drive/MyDrive/Thesis/Data/smiles_filtered_579_median.csv \\\n",
        "                           --features_path ../drive/MyDrive/Thesis/Data/HTSFP_smiles.npz \\\n",
        "                           --checkpoint_path ../drive/MyDrive/Thesis/Model/grover_large.pt \\\n",
        "                           --fingerprint_source both \\\n",
        "                           --output ../drive/MyDrive/Thesis/Data/fp_large.npz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm0LmXiVn3t7"
      },
      "source": [
        "### Inspect Fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PmveN4N7oI-k",
        "outputId": "c2982665-5dee-473d-e70d-093437164562"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/grover'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# inspect current working directory\n",
        "%pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF-vpBy6n32h",
        "outputId": "e00949be-250a-4811-dc3b-a0c803eabaf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['smiles', 'fps'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "file_path = '../drive/MyDrive/Thesis/Data/fp_large.npz'\n",
        "data = np.load(file_path, allow_pickle=True)\n",
        "print(data.keys())  # Display the keys or attributes in the file\n",
        "# Access and examine the data as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Qc84MfpeAv",
        "outputId": "091ab5a6-91cc-42f5-836c-e3086f6c29ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         CC1=C(C(=NS1)S(=O)(=O)/C(=N/NC2=CC=CC(=C2)C(F)...\n",
              "1         CC(C)(C)N1C(=NN=N1)C(C2=CC=CC=C2OC)N3CCCC4=CC=...\n",
              "2                    CC1=NN=C(N1/N=C\\C2=CC=C(C=C2)C(=O)OC)C\n",
              "3                               C1=CC=C2C(=C1)C=C(C(=O)O2)N\n",
              "4         C1COCCN1S(=O)(=O)C2=C(C=CC(=C2)C(=O)NC3=CC4=C(...\n",
              "                                ...                        \n",
              "324187    C1CC(C1)C(=O)N2CCC3=C2C=CC(=C3)S(=O)(=O)N4CCC5...\n",
              "324188    CCOC(=O)C1=C(N(N=C1)C2=NC=NC3=C2C=NN3CC4=CC=CC...\n",
              "324189                          CN1CCN(CC1)CC(C2=CC=CC=C2)O\n",
              "324190    CCCC1=NC2=C(C(=C(S2)C)C)C(=N1)SCC(=O)N3CCC4=CC...\n",
              "324191    CC1=CC2=NC3=C(C=C2C=C1)C(=C(S3)C(=O)N4CC(=O)NC...\n",
              "Name: smiles, Length: 324192, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['smiles']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt89Qb0Opmyx",
        "outputId": "754c2f44-21dc-45c6-a2ef-560015169cbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-7.89292872e-01,  6.27004743e-01, -7.91928768e-01,  8.19022357e-01,\n",
              "        1.20746446e+00, -6.24105275e-01, -3.46923053e-01,  8.49374890e-01,\n",
              "        8.20919037e-01, -1.54049575e-01,  8.29877853e-01,  4.32644606e-01,\n",
              "        5.30687988e-01,  3.36008608e-01, -7.81888783e-01,  2.69850731e-01,\n",
              "        6.18666649e-01,  4.25872773e-01,  5.46775401e-01,  2.79903322e-01,\n",
              "       -8.91439080e-01, -9.49716289e-03, -1.70764938e-01, -2.51722157e-01,\n",
              "       -6.84444308e-01,  9.06562984e-01, -2.95437515e-01,  4.21518534e-02,\n",
              "        4.10546929e-01, -7.60677934e-01, -7.80300856e-01,  7.80405283e-01,\n",
              "       -9.63750303e-01,  5.04185930e-02,  1.18975961e+00,  5.15425801e-01,\n",
              "       -2.83948660e-01, -9.82012689e-01, -2.98990875e-01,  4.26783040e-02,\n",
              "       -9.33582306e-01, -6.60347641e-01, -7.30285347e-01, -7.36297131e-01,\n",
              "       -8.12867165e-01,  2.50640601e-01,  3.30958143e-02, -5.80460727e-01,\n",
              "       -5.62716782e-01,  5.79053521e-01,  7.84362674e-01, -4.43908900e-01,\n",
              "        6.40295148e-01,  6.09267175e-01,  3.53539050e-01, -8.25176418e-01,\n",
              "       -1.01936173e+00,  1.70370564e-01,  5.90038419e-01, -9.89060402e-01,\n",
              "        8.13774109e-01,  3.89836401e-01, -4.78592128e-01,  5.20094812e-01,\n",
              "       -8.30688953e-01,  8.42934132e-01,  8.64690423e-01,  6.80442452e-01,\n",
              "        6.02820039e-01,  4.25647665e-03, -9.38837171e-01, -1.36332512e-01,\n",
              "        6.55890048e-01,  9.88287151e-01,  8.95878255e-01,  7.12538123e-01,\n",
              "       -1.09892762e+00,  5.66313088e-01, -9.74002063e-01, -5.85918725e-01,\n",
              "       -1.31455794e-01, -5.29134333e-01, -1.09108257e+00, -7.49993801e-01,\n",
              "       -2.64782429e-01,  1.01291776e+00,  1.11097491e+00, -7.29593575e-01,\n",
              "        8.29851925e-01,  3.76613915e-01,  1.11196125e+00,  9.28918779e-01,\n",
              "       -1.34230781e+00, -8.25209320e-01,  2.67516255e-01, -1.84003711e-01,\n",
              "        6.83035374e-01, -8.32260549e-01, -7.98111379e-01, -9.21037138e-01,\n",
              "       -5.49227417e-01, -3.87995899e-01,  1.90254077e-01,  1.93708301e-01,\n",
              "        8.11076581e-01, -7.59598255e-01, -8.33152950e-01, -4.76480305e-01,\n",
              "        6.91054463e-02, -5.77809751e-01,  8.63418221e-01,  4.02918071e-01,\n",
              "       -8.71556103e-01, -9.07467306e-01, -6.16045773e-01,  2.60324210e-01,\n",
              "        7.46195912e-01, -6.20374203e-01, -4.17672247e-01,  3.80941242e-01,\n",
              "       -5.13017416e-01, -4.74504381e-01, -1.04015243e+00, -8.34035575e-01,\n",
              "       -1.09075105e+00, -5.28190613e-01, -7.42559314e-01, -7.58582830e-01,\n",
              "        6.58231437e-01, -3.47643763e-01, -7.63485730e-01,  7.42834270e-01,\n",
              "       -3.06419522e-01,  4.06932563e-01, -6.02950692e-01,  6.70587644e-02,\n",
              "       -4.21677738e-01, -1.86553955e-01,  8.62533033e-01,  1.08807254e+00,\n",
              "        7.86793351e-01,  9.93768394e-01,  8.47102940e-01,  5.42005837e-01,\n",
              "       -2.57974923e-01, -2.84801930e-01, -8.99963677e-01, -7.45623410e-01,\n",
              "       -6.82408035e-01,  4.60331202e-01,  4.09332523e-03,  9.64273155e-01,\n",
              "       -9.70841408e-01,  1.40995908e+00,  9.67498124e-01, -1.16450536e+00,\n",
              "       -1.83561370e-01, -4.28680420e-01,  5.76689124e-01,  5.45831978e-01,\n",
              "        4.40412432e-01,  8.80142629e-01, -4.49211925e-01, -2.23208576e-01,\n",
              "        3.74061912e-01, -1.09040248e+00, -7.17695177e-01,  8.05142701e-01,\n",
              "        4.96431321e-01, -8.16835344e-01,  2.12201506e-01,  3.47760648e-01,\n",
              "        8.61930788e-01,  3.56836729e-02, -3.95608991e-01,  7.96224117e-01,\n",
              "        2.90590107e-01, -5.08603573e-01,  7.83870339e-01,  1.32663712e-01,\n",
              "        1.65740415e-01, -7.37913132e-01,  7.63222694e-01,  8.25147092e-01,\n",
              "        6.84470952e-01, -2.60484755e-01,  9.06798005e-01, -1.02454662e+00,\n",
              "        7.09189415e-01, -3.39642279e-02, -1.31178224e+00,  5.75410306e-01,\n",
              "       -8.23495805e-01, -1.12630880e+00,  1.05910766e+00,  1.09357786e+00,\n",
              "        8.14246118e-01, -8.00102413e-01,  5.89084387e-01,  7.33778536e-01,\n",
              "        3.90776128e-01, -8.53640378e-01,  3.69128883e-01,  1.08256519e+00,\n",
              "        4.57358897e-01,  5.02652586e-01,  6.46554947e-01,  6.07077539e-01,\n",
              "       -5.05878218e-02,  4.09405529e-01, -1.10960197e+00, -4.58466977e-01,\n",
              "       -1.53377533e-01, -3.68790597e-01, -4.84656185e-01, -6.93117142e-01,\n",
              "        1.94436908e-01, -4.10850346e-01,  1.05682397e+00, -4.36738491e-01,\n",
              "        3.69948119e-01, -5.96931279e-01,  5.12586534e-01, -6.61236882e-01,\n",
              "       -1.07768500e+00, -5.34021199e-01,  1.10589780e-01, -2.73138911e-01,\n",
              "        7.04796851e-01, -8.60049725e-01,  4.89124030e-01,  5.71507275e-01,\n",
              "        8.05455327e-01,  8.17423761e-01,  3.76526654e-01,  5.70122182e-01,\n",
              "        1.22478807e+00,  8.06515396e-01,  5.58147907e-01,  1.05605745e+00,\n",
              "        8.64132345e-01,  3.50251824e-01, -4.25615370e-01, -5.12242496e-01,\n",
              "        9.76473033e-01,  3.95293325e-01,  6.88971639e-01, -7.65239894e-01,\n",
              "        2.28770807e-01, -1.50419429e-01, -5.11549890e-01,  6.09214783e-01,\n",
              "       -1.90916210e-02,  5.75046241e-01, -3.25507611e-01, -5.46592176e-01,\n",
              "       -4.42249596e-01,  1.18468873e-01,  9.56674516e-01, -6.24543786e-01,\n",
              "       -1.31454563e+00,  9.32352483e-01,  2.01566607e-01, -4.13119406e-01,\n",
              "       -3.02175581e-01, -1.08459747e+00, -6.02454066e-01, -8.82627308e-01,\n",
              "       -1.52580783e-01, -8.01942825e-01, -2.82145590e-01,  3.32148939e-01,\n",
              "       -8.13731372e-01,  2.85260767e-01,  6.05487525e-01, -6.32073998e-01,\n",
              "        6.85528934e-01,  2.81035453e-01, -7.29792953e-01, -6.54860377e-01,\n",
              "        9.43124294e-01,  7.34097064e-01,  8.49223912e-01,  3.75893921e-01,\n",
              "       -5.49502850e-01,  3.82402539e-01, -9.05456960e-01, -1.03402066e+00,\n",
              "       -7.84267008e-01, -5.10300934e-01,  3.81747693e-01, -1.05598772e+00,\n",
              "        9.70460415e-01, -1.06613696e-01,  2.52404332e-01,  7.10138500e-01,\n",
              "       -2.15037376e-01,  1.51259348e-01, -6.64014161e-01, -1.33011520e+00,\n",
              "       -8.92721653e-01, -8.85272980e-01, -5.37119687e-01,  6.28729761e-01,\n",
              "       -7.85623610e-01, -2.02061579e-01,  8.83942127e-01, -7.79425144e-01,\n",
              "        9.81220663e-01, -5.96472681e-01,  6.15981579e-01, -1.33354080e+00,\n",
              "        6.50141835e-01, -4.36933100e-01,  3.23466927e-01, -4.49645013e-01,\n",
              "        3.86507750e-01,  4.62588996e-01, -6.90142810e-01, -9.36101437e-01,\n",
              "       -9.66111600e-01,  1.76955342e-01, -5.16034007e-01,  5.39243758e-01,\n",
              "       -6.18624508e-01,  4.29617256e-01,  1.05038345e+00,  4.23175156e-01,\n",
              "       -1.91498920e-01,  2.93238789e-01,  5.94043672e-01,  2.67622739e-01,\n",
              "        3.73202354e-01,  7.47645020e-01, -4.37063694e-01,  6.36118233e-01,\n",
              "        1.08607805e+00,  9.60735008e-02, -3.81882012e-01, -9.27920118e-02,\n",
              "        6.17820859e-01,  1.28330076e+00,  1.82400987e-01,  4.37673956e-01,\n",
              "       -1.17320490e+00,  8.68840739e-02,  5.31407058e-01, -4.77176249e-01,\n",
              "        4.24347967e-01,  6.36791959e-02,  7.84949243e-01, -3.08462065e-02,\n",
              "        5.36161721e-01,  5.77724159e-01, -9.22201276e-01,  1.24862421e+00,\n",
              "       -1.84822544e-01,  3.60486746e-01, -5.83231807e-01,  2.48504043e-01,\n",
              "       -3.41626137e-01,  1.02210796e+00,  5.29371023e-01, -2.04960808e-01,\n",
              "       -8.71386349e-01,  8.10082853e-01, -7.78127074e-01, -6.36644244e-01,\n",
              "       -1.30807257e+00, -5.64692318e-01, -1.04077721e+00, -3.30281645e-01,\n",
              "        6.87083676e-02,  2.72849560e-01, -4.19279158e-01, -2.92055488e-01,\n",
              "        8.62063348e-01,  1.16372001e+00, -4.23962086e-01,  3.10924381e-01,\n",
              "        1.67223915e-01,  1.33485049e-01,  5.13256252e-01, -7.46401429e-01,\n",
              "        4.63318020e-01,  7.54587054e-01, -4.50622857e-01, -2.31136754e-01,\n",
              "       -7.74131000e-01, -7.83958614e-01,  1.32950783e-01, -8.83010507e-01,\n",
              "       -7.53608882e-01, -6.52010858e-01, -5.86712539e-01,  9.81840730e-01,\n",
              "       -2.82910820e-02,  1.52119875e+00,  3.51683378e-01, -5.47567546e-01,\n",
              "        1.96076362e-05,  1.11832820e-01,  1.06450796e-01,  1.77349940e-01,\n",
              "        1.87814608e-01,  1.10053547e-01,  1.68671876e-01,  1.19390793e-01,\n",
              "        1.85865715e-01,  1.19536787e-01,  1.19686596e-01,  7.26963431e-02,\n",
              "        1.26147002e-01,  7.79882073e-02,  6.10115886e-01,  2.82315880e-01,\n",
              "        6.89356852e-07,  4.40791845e-01,  5.46155453e-01,  4.19837415e-01,\n",
              "        9.25841695e-11,  5.85610919e-17,  6.51996613e-01,  7.78625727e-01,\n",
              "        3.49110782e-01,  1.55699387e-01,  5.06393731e-01,  4.40084130e-01,\n",
              "        5.50254464e-01,  5.28931916e-01,  9.12710547e-01,  1.37062073e-01,\n",
              "        1.46173328e-01,  9.99998987e-01,  3.33629578e-01,  5.03374219e-01,\n",
              "        5.81981719e-01,  1.75720215e-01,  5.30076101e-02,  8.19622815e-01,\n",
              "        5.30076101e-02,  5.68835549e-02,  3.24286625e-10,  4.40142676e-02,\n",
              "        4.33838934e-01,  1.69037938e-01,  4.63312745e-01,  2.10664883e-01,\n",
              "        1.52884930e-01,  7.07278669e-01,  1.24047369e-01,  9.93858718e-22,\n",
              "        1.42492250e-01,  6.29631355e-02,  6.35287762e-01,  4.82993010e-15,\n",
              "        3.85834038e-01,  1.68438017e-01,  7.31660187e-01,  9.82373953e-02,\n",
              "        1.00000000e+00,  4.66310263e-01,  0.00000000e+00,  1.14242660e-21,\n",
              "        2.40245506e-23,  1.77145794e-01,  6.12260163e-01,  8.69873345e-01,\n",
              "        3.60875253e-15,  1.45980120e-01,  1.73556720e-22,  1.18093646e-10,\n",
              "        5.99833801e-02,  9.05498609e-08,  4.60978367e-10,  1.57072380e-01,\n",
              "        7.89781868e-01,  6.44137561e-02,  7.28170276e-01,  2.75008846e-02,\n",
              "        1.20265670e-01,  3.24090809e-01,  5.71146190e-01,  1.67096868e-01,\n",
              "        2.05072373e-01,  8.78622232e-24,  5.31226337e-01,  4.50414181e-01,\n",
              "        2.92070925e-01,  5.30138095e-05,  6.99547827e-01,  6.03355110e-01,\n",
              "        6.95272019e-13,  7.09806383e-01,  9.86699045e-01,  4.00590718e-01,\n",
              "        1.20493060e-11,  2.86305002e-09,  2.37261027e-01,  4.66589361e-01,\n",
              "        2.99487760e-06,  9.85541642e-01,  5.30138095e-05,  1.02915592e-01,\n",
              "        5.30138095e-05,  5.00000000e-01,  3.84710461e-01,  5.30138095e-05,\n",
              "        5.30138095e-05,  9.99817133e-01,  5.30138095e-05,  0.00000000e+00,\n",
              "        9.02640224e-01,  2.02868339e-02,  5.70867843e-19,  9.99247134e-01,\n",
              "        9.97862101e-01,  7.10542736e-15,  5.83707561e-13,  1.19880645e-20,\n",
              "        1.65079549e-01,  1.67040631e-01,  1.66498333e-01,  1.66486815e-01,\n",
              "        2.02864662e-01,  6.93658814e-02,  7.10542736e-15,  1.68346480e-01,\n",
              "        1.67982936e-01,  6.87189861e-10,  5.98257124e-01,  1.64332628e-01,\n",
              "        8.37776926e-04,  1.66325733e-01,  1.63034141e-01,  1.65079549e-01,\n",
              "        9.56970467e-08,  3.49708920e-08,  1.68206170e-01,  1.65806860e-01,\n",
              "        1.67346597e-01,  7.13964596e-07,  2.64115097e-12,  9.99127924e-02,\n",
              "        2.86809132e-10,  3.77737850e-01,  4.50616796e-03,  1.33250251e-01,\n",
              "        6.35349631e-01,  1.61482916e-09,  9.14027333e-01,  2.09410544e-07,\n",
              "        7.10542736e-15,  4.99264270e-01,  1.64929405e-01,  7.60844767e-01,\n",
              "        2.11164361e-16,  1.16815879e-09,  9.09514666e-01,  6.24601426e-10,\n",
              "        1.68149188e-01,  1.65450722e-01,  1.17110260e-13,  0.00000000e+00,\n",
              "        1.64668873e-01,  1.66924730e-01,  0.00000000e+00,  5.10071345e-08,\n",
              "        7.10542736e-15,  1.54654115e-01,  2.79420944e-22,  0.00000000e+00,\n",
              "        1.67639732e-01,  6.31499277e-25,  1.68186128e-01,  9.08850227e-03,\n",
              "        1.68363199e-01,  8.26542307e-11,  1.56346351e-01,  0.00000000e+00,\n",
              "        0.00000000e+00,  2.11354233e-02,  2.11354233e-02,  2.38815573e-20,\n",
              "        0.00000000e+00,  8.33672445e-25,  5.30138095e-05,  1.56951070e-01,\n",
              "        4.03434512e-08,  1.55259202e-23,  1.59306119e-17,  5.76610089e-14,\n",
              "        2.95798941e-11,  1.68378368e-01,  1.67380184e-01,  1.48151460e-18,\n",
              "        2.32414988e-16,  4.70359822e-08,  1.66633397e-01,  9.30688262e-01],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['fps'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I3W92KKGmPX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cpu')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOCWFjwoiTNgnfTMVAT//E+",
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
