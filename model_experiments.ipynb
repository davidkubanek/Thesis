{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidkubanek/Thesis/blob/main/model_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpnAQeFgIIKA"
      },
      "source": [
        "# CONCERTO architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1jm2t5MI4af",
        "outputId": "797f2597-b0bc-45b3-e5b9-c41a939dd8e2"
      },
      "outputs": [],
      "source": [
        "# for running in colab\n",
        "!pip install dgl\n",
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T69lAzjYIIKB",
        "outputId": "9d946359-3615-4514-b5f6-596ec27da9ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  plt.rcParams[\"font.family\"] = \"Palatino\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "import wandb\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "# check if cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQK8GKzgKVqk",
        "outputId": "56963eed-6b15-4fe9-d1f6-c68d51acd186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG-9VYyW7Dud"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eR47vh5vf_Se"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def prepare_datalist(matrix_df, args, graph_fp=True, grover_fp=None):\n",
        "    '''\n",
        "    Convert matrix dataframe to a data_list with pytorch geometric graph data, fingerprints and labels.\n",
        "    Inputs:\n",
        "        matrix_df: dataframe of SMILES, assays and bioactivity labels\n",
        "        args: arguments\n",
        "        graph_fp: if True, includes graph embedding fingerprints into data_list\n",
        "        grover_fp: if True, includes GROVER graph transformer embedding fingerprints into data_list\n",
        "    Outputs:\n",
        "        data_list: list of data objects\n",
        "    '''\n",
        "    # only use subset of data (assays and data points)\n",
        "    assay_list = args['assay_list']\n",
        "    num_assays = args['num_assays']\n",
        "    assay_start = args['assay_start']\n",
        "    num_data_points = args['num_data_points']\n",
        "\n",
        "    # get binary target labels\n",
        "    y = matrix_df[assay_list[assay_start:assay_start+num_assays]].values[:num_data_points]\n",
        "\n",
        "    # get SMILES strings\n",
        "    data = matrix_df['SMILES'].values[:num_data_points]\n",
        "\n",
        "    if graph_fp is True: # add graph fingerprint\n",
        "        GraphDataset = GraphDatasetClass()\n",
        "        # create pytorch geometric graph data list\n",
        "        data_list = GraphDataset.create_pytorch_geometric_graph_data_list_from_smiles_and_labels(data, y)\n",
        "    else: # create simple data_list without graph fingerprint\n",
        "      data_list = []\n",
        "      for label in y:\n",
        "          # construct Pytorch Geometric data object and append to data list\n",
        "          data_list.append(Data(y = label.reshape(1, -1)))\n",
        "\n",
        "    # add fingerprint data to each graph\n",
        "    for i, smile in tqdm(enumerate(data), desc='Adding fingerprints...', total=len(data)):\n",
        "        fp = convert_smile_to_fp_bit_string(smile)\n",
        "        data_list[i].fp = fp\n",
        "\n",
        "\n",
        "    # add grover fingerprint to each graph\n",
        "    if grover_fp is not None:\n",
        "        for i, gfp in tqdm(enumerate(grover_fp['fps'][:args['num_data_points']]), desc='Adding grover embedding...', total=len(data)):\n",
        "          data_list[i].grover_fp = torch.tensor(gfp)\n",
        "\n",
        "    print(f'Example of a graph data object: {data_list[0]}')\n",
        "\n",
        "    return data_list\n",
        "\n",
        "def prepare_splits(data_list, args):\n",
        "\n",
        "    data_list = data_list[:args['num_data_points']]\n",
        "\n",
        "    data_splits = {}\n",
        "    # split into train and test\n",
        "    train_dataset = [d.to(args['device']) for d in data_list[:int(len(data_list)*0.8)]]\n",
        "    data_splits['test'] = [d.to(args['device']) for d in data_list[int(len(data_list)*0.8):]]\n",
        "\n",
        "    # split into train and validation\n",
        "    data_splits['val'] = train_dataset[:int(len(train_dataset)*0.25)]\n",
        "    data_splits['train'] = train_dataset[int(len(train_dataset)*0.25):]\n",
        "\n",
        "    print(f'Number of training graphs:', len(data_splits['train']))\n",
        "    print(f'Number of validation graphs:', len(data_splits['val']))\n",
        "    print(f'Number of test graphs:', len(data_splits['test']))\n",
        "    print(f'Example of a graph data object: {data_list[0]}')\n",
        "\n",
        "    return data_splits\n",
        "\n",
        "\n",
        "def prepare_dataloader(data_splits, args):\n",
        "    '''\n",
        "    Get dataloader dictionary from data_list with desired batch_size\n",
        "    '''\n",
        "    # create data loaders\n",
        "    dataloader = {}\n",
        "    dataloader['train'] = DataLoader(data_splits['train'], batch_size=args['batch_size'], shuffle=True)\n",
        "    dataloader['val'] = DataLoader(data_splits['val'], batch_size=args['batch_size'], shuffle=False)\n",
        "    dataloader['test'] = DataLoader(data_splits['test'], batch_size=args['batch_size'], shuffle=False)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def analyze_dataset(dataset, args):\n",
        "    '''\n",
        "    Analyze the distribution of positive classes in the dataset\n",
        "    '''\n",
        "    positive = []\n",
        "    for i in range(len(dataset)):\n",
        "        positive.append(dataset[i].y[0].sum().item())\n",
        "\n",
        "\n",
        "    num_assays = args['num_assays']\n",
        "    # make histogram of the number of positive\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    # define bins\n",
        "    bins = np.linspace(0, num_assays, num_assays+1)-0.5\n",
        "    plt.hist(positive, bins=bins, alpha=0.5, label='train')\n",
        "    num_assays = args['num_assays']\n",
        "    plt.xlabel(f'# of positive hits in target vector (out of {num_assays})')\n",
        "    plt.ylabel('Number of data points')\n",
        "    plt.title('Histogram of positive class distribution')\n",
        "    plt.show()\n",
        "\n",
        "    # for i in range(num_assays+1):\n",
        "    #     print(f'Number of data points with {i} positive targets: ', (np.array(positive) == i).sum(), f'({(np.array(positive) == i).sum()/len(positive)*100:.2f}%)')\n",
        "\n",
        "def data_explore(dataloader):\n",
        "    '''\n",
        "    Explore the data\n",
        "    '''\n",
        "    # check proportion of positive and negative samples across each assay\n",
        "    pos = torch.zeros(args['num_assays'])\n",
        "    for data in dataloader:  # Iterate in batches over the training dataset\n",
        "        # print('inputs:')\n",
        "        # print(' x:', data.x.shape, '| y:',data.y.shape, '| fp:',data.fp.shape, '| grover:', data.grover_fp.shape)\n",
        "        pos += data.y.sum(axis=0)\n",
        "        #  print(data.y.sum(axis=0))\n",
        "    print('# positive samples:', pos)\n",
        "    print(torch.round((pos/len(dataloader.dataset)*100),decimals=2),'% are positive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bFUFuaaP7MeT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "directory = 'data/'\n",
        "#directory = '/content/drive/MyDrive/Thesis/Data/'\n",
        "\n",
        "# Specify the path where you saved the dictionary\n",
        "load_path = directory + 'final/datalist_no_out.pkl'\n",
        "\n",
        "# Load the dictionary using pickle\n",
        "with open(load_path, 'rb') as f:\n",
        "    data_list = pickle.load(f)\n",
        "\n",
        "\n",
        "# load the assay groups\n",
        "with open(directory + 'info/cell_based_high_hr.txt', 'r') as file:\n",
        "    lines = file.read().splitlines()\n",
        "cell_based_high_hr = list(map(str, lines))\n",
        "with open(directory + 'info/cell_based_med_hr.txt', 'r') as file:\n",
        "    lines = file.read().splitlines()\n",
        "cell_based_med_hr = list(map(str, lines))\n",
        "with open(directory + 'info/cell_based_low_hr.txt', 'r') as file:\n",
        "    lines = file.read().splitlines()\n",
        "cell_based_low_hr = list(map(str, lines))\n",
        "with open(directory + 'info/non_cell_based_high_hr.txt', 'r') as file:\n",
        "    lines = file.read().splitlines()\n",
        "non_cell_based_high_hr = list(map(str, lines))\n",
        "with open(directory + 'info/non_cell_based_med_hr.txt', 'r') as file:\n",
        "    lines = file.read().splitlines()\n",
        "non_cell_based_med_hr = list(map(str, lines))\n",
        "with open(directory + 'info/non_cell_based_low_hr.txt', 'r') as file:\n",
        "    lines = file.read().splitlines()\n",
        "non_cell_based_low_hr = list(map(str, lines))\n",
        "# load assay order\n",
        "with open(directory + 'info/assay_order.txt', 'r') as f:\n",
        "    assay_order = [line.strip() for line in f.readlines()]\n",
        "\n",
        "args = {}\n",
        "args['assay_order'] = assay_order\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYWyacYyIIKG"
      },
      "source": [
        "# Models\n",
        "### GCN and GCN_FP\n",
        "- GCN: graph embedding followed by a final classification layer\n",
        "- GCN_FP: graph + fingerprints embedding followed by a final classification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1q43d46hIIKG"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    '''\n",
        "    Define a Graph Convolutional Network (GCN) model architecture.\n",
        "    Can include 'graph' only or 'graph + fingerprints' embedding before final classification layer.\n",
        "    '''\n",
        "    def __init__(self, args):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "\n",
        "        num_node_features = args['num_node_features']\n",
        "        hidden_channels = args['hidden_channels']\n",
        "        num_classes = args['num_assays']\n",
        "        if args['model'] == 'GCN_FP':\n",
        "            fp_dim = args['fp_dim']\n",
        "        else:\n",
        "            fp_dim = 0\n",
        "\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin = Linear(hidden_channels + fp_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch, fp=None):\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # if also using fingerprints\n",
        "        if fp is not None:\n",
        "            # reshape fp to batch_size x fp_dim\n",
        "            fp = fp.reshape(x.shape[0], -1)\n",
        "            # concatenate graph node embeddings with fingerprint\n",
        "            # print('BEFORE CONCAT x:',x.shape, 'fp:', fp.shape)\n",
        "            x = torch.cat([x, fp], dim=1)\n",
        "            # print('AFTER CONCAT x:',x.shape)\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cENu4SMIIKG"
      },
      "source": [
        "### FP, GROVER and GROVER_FP\n",
        "- FP: fingerprints embedding followed by a final classification layer\n",
        "- GROVER: graph transformer embedding followed by a final classification layer\n",
        "- GROVER_FP: graph transformer + fingerprints embedding followed by a final classification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PXTwqghIIIKG"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LinearBlock(nn.Module):\n",
        "\t\"\"\" basic block in an MLP, with dropout and batch norm \"\"\"\n",
        "\n",
        "\tdef __init__(self, in_feats, out_feats, dropout=0.1):\n",
        "\t\tsuper(LinearBlock, self).__init__()\n",
        "\t\tself.linear = nn.Linear(in_feats, out_feats)\n",
        "\t\tself.bn = nn.BatchNorm1d(out_feats)\n",
        "\t\tself.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# ReLU activation, batch norm, dropout on layer\n",
        "\t\treturn self.bn(self.dropout(F.relu(self.linear(x))))\n",
        "\n",
        "def construct_mlp(in_dim, out_dim, hidden_dim, hidden_layers, dropout=0.1):\n",
        "\t\"\"\"\n",
        "\tConstructs an MLP with specified dimensions.\n",
        "\t\t- total number of layers = hidden_layers + 1 (the + 1 is for the output linear)\n",
        "\t\t- no activation/batch norm/dropout on output layer\n",
        "\t\"\"\"\n",
        "\n",
        "\tassert hidden_layers >= 1, hidden_layers\n",
        "\tmlp_list = []\n",
        "\tmlp_list.append(LinearBlock(in_dim,hidden_dim,dropout=dropout))\n",
        "\tfor i in range(hidden_layers-1):\n",
        "\t\tmlp_list.append(LinearBlock(hidden_dim,hidden_dim,dropout=dropout))\n",
        "\n",
        "\t# no activation/batch norm/dropout on output layer\n",
        "\tmlp_list.append(nn.Linear(hidden_dim,out_dim))\n",
        "\tmlp = nn.Sequential(*mlp_list)\n",
        "\treturn mlp\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\t'''\n",
        "\tMLP with optional Grover fingerprints.\n",
        "\tCustomizable number of layers, hidden dimensions, and dropout.\n",
        "\t'''\n",
        "\tdef __init__(self, args):\n",
        "\n",
        "\t\tsuper(MLP, self).__init__()\n",
        "\n",
        "\t\tself.model_type = args['model']\n",
        "\t\tself.fp_dim = args['fp_dim'] # can be 0\n",
        "\t\tself.grover_fp_dim = args['grover_fp_dim'] # can be 0\n",
        "\t\tself.hidden_dim = args['hidden_channels']\n",
        "\t\tself.output_dim = args['num_assays']\n",
        "\t\tself.num_layers = args['num_layers']\n",
        "\t\tself.dropout = args['dropout']\n",
        "\n",
        "\t\tassert self.model_type in ['FP','GROVER','GROVER_FP'], f'model type not supported: {self.model_type}'\n",
        "\n",
        "\t\tif self.model_type == 'FP':\n",
        "\t\t\tself.grover_fp_dim = 0\n",
        "\t\telif self.model_type == 'GROVER':\n",
        "\t\t\tself.fp_dim = 0\n",
        "\n",
        "\t\tself.ff_layers = construct_mlp(\n",
        "\t\t\tself.fp_dim + self.grover_fp_dim,\n",
        "\t\t\tself.output_dim,\n",
        "\t\t\tself.hidden_dim,\n",
        "\t\t\tself.num_layers,\n",
        "\t\t\tself.dropout\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\n",
        "\n",
        "\t\tif self.model_type == 'FP': # only fp is used\n",
        "\t\t\tfingerprints = data.fp\n",
        "\t\t\t# reshape fp to batch_size x fp_dim\n",
        "\t\t\tfingerprints = fingerprints.reshape(int(fingerprints.shape[0]/self.fp_dim), -1)\n",
        "\n",
        "\t\t\toutput = self.ff_layers(fingerprints)\n",
        "\n",
        "\t\telif self.model_type == 'GROVER': # only grover is used\n",
        "\t\t\t# reshape grover_fp to batch_size x grover_fp_dim\n",
        "\t\t\tgrover_fp = data.grover_fp\n",
        "\t\t\tgrover_fp = grover_fp.reshape(int(grover_fp.shape[0]/self.grover_fp_dim), -1)\n",
        "\n",
        "\t\t\toutput = self.ff_layers(grover_fp)\n",
        "\n",
        "\t\telif self.model_type == 'GROVER_FP': #grover and fp are concatenated\n",
        "\t\t\tfingerprints = data.fp\n",
        "\t\t\t# reshape fp to batch_size x fp_dim\n",
        "\t\t\tfingerprints = fingerprints.reshape(int(fingerprints.shape[0]/self.fp_dim), -1)\n",
        "\t\t\t# reshape grover_fp to batch_size x grover_fp_dim\n",
        "\t\t\tgrover_fp = data.grover_fp\n",
        "\t\t\tgrover_fp = grover_fp.reshape(int(grover_fp.shape[0]/self.grover_fp_dim), -1)\n",
        "\n",
        "\t\t\toutput = self.ff_layers(torch.cat([fingerprints, grover_fp], dim=1))\n",
        "\n",
        "\n",
        "\t\treturn output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMXuJkTGIIKH"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "A3SbXTXlIIKH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "\n",
        "class TrainManager:\n",
        "\n",
        "    def __init__(self, dataloader, args, model=None):\n",
        "\n",
        "        self.args = args\n",
        "        self.num_assays = args['num_assays']\n",
        "        self.num_node_features = args['num_node_features']\n",
        "        self.hidden_channels = args['hidden_channels']\n",
        "\n",
        "        if not model:\n",
        "            # initialize model depending on model type\n",
        "            if args['model'] in ['GCN','GCN_FP']:\n",
        "                self.model = GCN(args)\n",
        "            elif args['model'] in ['FP','GROVER','GROVER_FP']:\n",
        "              self.model = MLP(args)\n",
        "        else:\n",
        "            self.model = model\n",
        "\n",
        "        self.model.to(args['device'])\n",
        "        print(\"Model is on device:\", next(self.model.parameters()).device)\n",
        "        total_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        print(f'Total number of parameters: {total_params}')\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=args['lr'])\n",
        "        # decay learning rate\n",
        "        self.scheduler = lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', factor=args['lr_decay_factor'])\n",
        "\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.curr_epoch = 0\n",
        "\n",
        "        # logging\n",
        "        self.eval_metrics = {}\n",
        "        self.eval_metrics['loss'] = []\n",
        "        self.eval_metrics['acc_train'] = []\n",
        "        self.eval_metrics['acc_test'] = []\n",
        "        self.eval_metrics['auc_train'] = []\n",
        "        self.eval_metrics['auc_test'] = []\n",
        "        self.eval_metrics['precision_train'] = []\n",
        "        self.eval_metrics['precision_test'] = []\n",
        "        self.eval_metrics['recall_train'] = []\n",
        "        self.eval_metrics['recall_test'] = []\n",
        "        self.eval_metrics['f1_train'] = []\n",
        "        self.eval_metrics['f1_test'] = []\n",
        "\n",
        "\n",
        "    def train(self, epochs=100, log=False, wb_log=False):\n",
        "        '''\n",
        "        Train the model for a given number of epochs.\n",
        "        '''\n",
        "\n",
        "        self.wb_log = wb_log\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            self.model.train()\n",
        "            cum_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Iterate in batches over the training dataset\n",
        "            for data in tqdm(self.dataloader['train'], desc=f'Epoch [{self.curr_epoch}/{epochs}]', total=int(len(self.dataloader['train'].dataset)/self.args['batch_size'])):\n",
        "\n",
        "                # clear gradients efficiently\n",
        "                for param in self.model.parameters():\n",
        "                    param.grad = None\n",
        "\n",
        "                # forward pass based on model type\n",
        "                if self.args['model'] == 'GCN':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch)\n",
        "                elif self.args['model'] == 'GCN_FP':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch, fp=data.fp)\n",
        "                elif self.args['model'] in ['FP','GROVER','GROVER_FP']:\n",
        "                    out = self.model(data)\n",
        "\n",
        "                # data.y = data.y.unsqueeze(1)\n",
        "                # print('data.y:',data.y.shape)\n",
        "                loss = self.criterion(out, data.y[:,args['assays_idx']])  # Compute the loss. (sigmoid inherent in loss)\n",
        "                loss.backward()  # Derive gradients.\n",
        "                self.optimizer.step()  # Update parameters based on gradients.\n",
        "                cum_loss += loss.item()\n",
        "\n",
        "            self.eval_metrics['loss'].append(cum_loss/len(self.dataloader['train']))\n",
        "            if wb_log is True:\n",
        "                wandb.log({'epoch': self.curr_epoch, \"loss\": cum_loss/len(self.dataloader['train'])})\n",
        "\n",
        "            epoch_time = time.time() - start_time\n",
        "\n",
        "            if log:\n",
        "                # evaluate\n",
        "                acc_train, auc_train, precision_train, recall_train, f1_train = self.eval(self.dataloader['train'])\n",
        "                acc_test, auc_test, precision_test, recall_test, f1_test = self.eval(self.dataloader['val'])\n",
        "\n",
        "\n",
        "                self.eval_metrics['acc_train'].append(acc_train)\n",
        "                self.eval_metrics['acc_test'].append(acc_test)\n",
        "                self.eval_metrics['auc_train'].append(auc_train)\n",
        "                self.eval_metrics['auc_test'].append(auc_test)\n",
        "                self.eval_metrics['precision_train'].append(precision_train)\n",
        "                self.eval_metrics['precision_test'].append(precision_test)\n",
        "                self.eval_metrics['recall_train'].append(recall_train)\n",
        "                self.eval_metrics['recall_test'].append(recall_test)\n",
        "                self.eval_metrics['f1_train'].append(f1_train)\n",
        "                self.eval_metrics['f1_test'].append(f1_test)\n",
        "\n",
        "                if wb_log is True:\n",
        "                    wandb.log({'epoch': self.curr_epoch, \"AUC train\": auc_train, \"AUC test\": auc_test, \"F1 train\": f1_train, \"F1 test\": f1_test, \"Precision train\": precision_train, \"Precision test\": precision_test, \"Recall train\": recall_train, \"Recall test\": recall_test})\n",
        "\n",
        "\n",
        "                if epoch % 10 == 0:\n",
        "                    print(f'Epoch: {self.curr_epoch}, Loss: {loss.item():.4f}, Train AUC: {auc_train:.4f}, Test AUC: {auc_test:.4f}')\n",
        "                    print(f'                        Train F1: {f1_train:.4f}, Test F1: {f1_test:.4f}')\n",
        "\n",
        "            self.curr_epoch += 1\n",
        "            self.scheduler.step(auc_test)\n",
        "\n",
        "\n",
        "        if wb_log is True:\n",
        "            wandb.log({'epoch': self.curr_epoch, \"avg epoch time\": epoch_time})\n",
        "\n",
        "    def eval(self, loader):\n",
        "        '''\n",
        "        Evaluate the model on a given dataset (train/val/test).\n",
        "        '''\n",
        "        start_time = time.time()\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        # print(\"Model is on device for eval:\", next(exp.model.parameters()).device)\n",
        "\n",
        "        correct = 0\n",
        "\n",
        "        gts = []\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "\n",
        "                # forward pass based on model type\n",
        "                if self.args['model'] == 'GCN':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch)\n",
        "                elif self.args['model'] == 'GCN_FP':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch, fp=data.fp)\n",
        "                elif self.args['model'] in ['FP','GROVER','GROVER_FP']:\n",
        "                    out = self.model(data)\n",
        "\n",
        "                # convert out to binary\n",
        "                pred = torch.round(torch.sigmoid(out))\n",
        "                preds.append(torch.round(torch.sigmoid(out)).tolist())\n",
        "                gts.append(data.y[:,args['assays_idx']].tolist())\n",
        "                # print('pred:', pred)\n",
        "                # print('data.y:', data.y)\n",
        "                # print('data.y eval:',data.y.shape)\n",
        "                # data.y = data.y.unsqueeze(1)\n",
        "                correct += int((pred == data.y[:,args['assays_idx']]).sum())  # Check against ground-truth labels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        preds = [b[i] for b in preds for i in range(len(b))]\n",
        "        gts = [b[i] for b in gts for i in range(len(b))]\n",
        "\n",
        "        auc = roc_auc_score(gts, preds)\n",
        "        # Calculate macro-averaged precision, recall, and F1 Score\n",
        "        precision = precision_score(gts, preds, average='macro', zero_division=0)\n",
        "        recall = recall_score(gts, preds, average='macro', zero_division=0)\n",
        "        f1 = f1_score(gts, preds, average='macro', zero_division=0)\n",
        "\n",
        "\n",
        "        acc = correct / (len(loader.dataset) * self.args['num_assays']) # Derive ratio of correct predictions.\n",
        "\n",
        "        self.eval_time = time.time() - start_time\n",
        "\n",
        "        if self.wb_log is True:\n",
        "            wandb.log({'epoch': self.curr_epoch, \"eval time\": self.eval_time})\n",
        "\n",
        "        return acc, auc, precision, recall, f1\n",
        "\n",
        "\n",
        "\n",
        "    def analyze(self):\n",
        "        '''\n",
        "        Plot the model performance.\n",
        "        '''\n",
        "\n",
        "        # plot side by side\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        ax1.plot(self.eval_metrics['loss'])\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title('Losses')\n",
        "\n",
        "        ax2.plot(self.eval_metrics['auc_train'], label='train')\n",
        "        ax2.plot(self.eval_metrics['auc_test'], label='test')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('AUC')\n",
        "        ax2.set_title('Area Under Curve')\n",
        "        ax2.legend()\n",
        "        # make main title for the whole plot\n",
        "        if args['model'] in ['GCN', 'GCN_FP']:\n",
        "            plt.suptitle(f'Model: {self.args[\"model\"]} | Node feats: {self.args[\"num_node_features\"]}, Hidden dim: {self.args[\"hidden_channels\"]}, Dropout: {self.args[\"dropout\"]}, Num data points: {self.args[\"num_data_points\"]}, Num assays: {self.args[\"num_assays\"]}, Num epochs: {self.curr_epoch}')\n",
        "        elif args['model'] in ['FP', 'GROVER', 'GROVER_FP']:\n",
        "            plt.suptitle(f'Model: {self.args[\"model\"]} | Num layers: {self.args[\"num_layers\"]}, Hidden dim: {self.args[\"hidden_channels\"]}, Dropout: {self.args[\"dropout\"]}, Num data points: {self.args[\"num_data_points\"]}, Num assays: {self.args[\"num_assays\"]}, Num epochs: {self.curr_epoch}')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def save_model(self, folder, filename, save_weights=True, save_logs=True):\n",
        "        print('saving experiment...')\n",
        "\n",
        "        filename += f'_{self.curr_epoch}e'\n",
        "        if save_weights:\n",
        "            torch.save(self.model.state_dict(), os.path.join(folder, filename+'.pt'))\n",
        "\n",
        "        #if save_logs:\n",
        "\n",
        "    def load_model(self, folder, filename):\n",
        "        print('loading model...')\n",
        "        self.model.load_state_dict(torch.load(os.path.join(folder, filename+'.pt')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxwqEHtDIIKH"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NDM8I94pr9DS"
      },
      "outputs": [],
      "source": [
        "args = {}\n",
        "args['device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# data parameters\n",
        "args['num_data_points'] = 324191 # all=324191 # number of data points to use\n",
        "#args['assay_list'] = cell_based_high_hr #for all: matrix_df.columns.values[1:]\n",
        "args['num_assays'] = 5 # number of assays to use (i.e., no. of output classes)\n",
        "args['assay_start'] = 0 # which assay to start from\n",
        "args['assay_order'] = assay_order\n",
        "args['num_node_features'] = 79 # number of node features in graph representation\n",
        "args['grover_fp_dim'] = 5000 #grover_fp['fps'][0].shape[0] # None  # dim of grover fingerprints\n",
        "args['fp_dim'] = 2215 # dim of fingerprints\n",
        "\n",
        "\n",
        "# training parameters\n",
        "args['model'] = 'GROVER_FP' # 'GCN', 'GCN_FP', 'FP', 'GROVER', 'GROVER_FP'\n",
        "args['num_layers'] = 5 # number of layers in MLP\n",
        "args['hidden_channels'] = 64 # 64\n",
        "args['dropout'] = 0.2\n",
        "args['batch_size'] = 256\n",
        "args['num_epochs'] = 100\n",
        "args['lr'] = 0.01\n",
        "#args['gradient_clip_norm'] = 1.0\n",
        "#args['network_weight_decay'] = 0.0001\n",
        "args['lr_decay_factor'] = 0.5\n",
        "\n",
        "# check batch size -> to include examples of classes\n",
        "# dropout maybe higher\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a3veHUzXggq",
        "outputId": "f83a38ea-568c-417f-8bd3-de24ac85633a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['743397', '624127', '2796', '1979', '602248', '1910', '2797']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cell_based_high_hr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GHHZCeMvXeVk"
      },
      "outputs": [],
      "source": [
        "# find indeces of assays in assay_list in assay_order\n",
        "# return list of indeces\n",
        "def find_assay_indeces(assay_list, assay_order):\n",
        "    indeces = []\n",
        "    for assay in assay_list:\n",
        "        indeces.append(assay_order.index(assay))\n",
        "    return indeces\n",
        "\n",
        "args['assay_list'] = ['2797']\n",
        "args['num_assays'] = 1\n",
        "args['assays_idx'] = find_assay_indeces(args['assay_list'], assay_order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhn2hx6QqAjC",
        "outputId": "90dec0f4-5c1c-4d6b-83b0-a0be90414ad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training graphs: 194514\n",
            "Number of validation graphs: 64838\n",
            "Number of test graphs: 64839\n",
            "Example of a graph data object: Data(x=[24, 79], edge_index=[2, 52], edge_attr=[52, 10], y=[1, 271], fp=[2215], grover_fp=[5000])\n"
          ]
        }
      ],
      "source": [
        "data_splits = prepare_splits(data_list, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPCwEq9PCwYI"
      },
      "source": [
        "### Sweeps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "q4KsLRLXN9KG"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {'goal': 'maximize', 'name': 'AUC test'},\n",
        "    }\n",
        "parameters_dict = {\n",
        "    'batch_size': {\n",
        "        'values': [128, 256, 512, 1014]\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.3, 0.5]\n",
        "        },\n",
        "    }\n",
        "\n",
        "parameters_dict.update({\n",
        "    'num_data_points': {\n",
        "        'value': args['num_data_points']},\n",
        "    'num_epochs': {\n",
        "        'value': args['num_epochs']},\n",
        "    'num_layers': {\n",
        "        'value': args['num_layers']},\n",
        "    'hidden_channels': {\n",
        "        'value': args['hidden_channels']},\n",
        "    'lr': {\n",
        "        'value': args['lr']}\n",
        "    })\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwNdYyGgheTU",
        "outputId": "54762017-d3c2-432c-fe51-ba0281f19038"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'method': 'bayes',\n",
              " 'metric': {'goal': 'maximize', 'name': 'AUC test'},\n",
              " 'parameters': {'batch_size': {'values': [128, 256, 512, 1014]},\n",
              "  'dropout': {'values': [0.3, 0.5]},\n",
              "  'num_data_points': {'value': 324191},\n",
              "  'num_epochs': {'value': 100},\n",
              "  'num_layers': {'value': 5},\n",
              "  'hidden_channels': {'value': 128},\n",
              "  'lr': {'value': 0.01}}}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sweep_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UMXJz4sNuCo",
        "outputId": "54bcf281-a16f-47d2-bc47-016fb2bd56b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: lek9qgmi\n",
            "Sweep URL: https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/sweeps/lek9qgmi\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"GDL_molecular_activity_prediction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "BinziYUTQwGY"
      },
      "outputs": [],
      "source": [
        "def run_sweep(data_splits, args):\n",
        "    # Create a custom run name dynamically\n",
        "    run_name = f\"{args['model']}\"\n",
        "\n",
        "    with wandb.init(config=args):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "\n",
        "        # with wandb.init(config=wandb.config) as run:\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        # config = wandb.config\n",
        "\n",
        "        args['batch_size'] = wandb.config.batch_size\n",
        "        args['dropout'] = wandb.config.dropout\n",
        "\n",
        "        # create dataset from data_list\n",
        "        dataloader = prepare_dataloader(data_splits, args)\n",
        "\n",
        "        # train model\n",
        "        exp = TrainManager(dataloader, args)\n",
        "        exp.train(epochs=2, log=True, wb_log=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YzkH-H-dos-s"
      },
      "outputs": [],
      "source": [
        "dataloader = prepare_dataloader(data_splits, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONNO-CpSo1eB",
        "outputId": "e5910f5e-61b6-4dd1-f5b7-7ca8b6d405d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1014"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataloader['train'].batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a8b130e755244f98b2860b512da44d43",
            "927687b91bd14816814a1bf86e971208",
            "6252098c7f1048f492450291583e301f",
            "b7798ae87814431e875a9455657d8ab8",
            "78a1a347adaa4d4e9949c454776efc5d",
            "ede939aa08c248aa8af7b30e61b4a7ba",
            "5e2f3a2781df46e3a47ce8962acd531b",
            "40aba29c28564f819c7d1cafb1235834"
          ]
        },
        "id": "NxiWVecC85c2",
        "outputId": "80b8ca8a-c62c-45ff-dc9d-7e913c62e8f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230816_192027-z2q91rkf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/runs/z2q91rkf' target=\"_blank\">good-sweep-4</a></strong> to <a href='https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/sweeps/kk90ey6b' target=\"_blank\">https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/sweeps/kk90ey6b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction' target=\"_blank\">https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/sweeps/kk90ey6b' target=\"_blank\">https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/sweeps/kk90ey6b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/runs/z2q91rkf' target=\"_blank\">https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/runs/z2q91rkf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on device: cuda:0\n",
            "Total number of parameters: 991105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [0/2]: 192it [00:15, 12.26it/s]                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.1641, Train AUC: 0.5000, Test AUC: 0.5000\n",
            "                        Train F1: 0.4859, Test F1: 0.4852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/2]: 192it [00:15, 12.32it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8b130e755244f98b2860b512da44d43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.204211…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC test</td><td>█▁</td></tr><tr><td>AUC train</td><td>▁█</td></tr><tr><td>F1 test</td><td>█▁</td></tr><tr><td>F1 train</td><td>▁█</td></tr><tr><td>Precision test</td><td>█▁</td></tr><tr><td>Precision train</td><td>▁█</td></tr><tr><td>Recall test</td><td>█▁</td></tr><tr><td>Recall train</td><td>▁█</td></tr><tr><td>avg epoch time</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▅▅▅▅█</td></tr><tr><td>eval time</td><td>█▁▇▁</td></tr><tr><td>loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC test</td><td>0.49998</td></tr><tr><td>AUC train</td><td>0.50013</td></tr><tr><td>F1 test</td><td>0.48518</td></tr><tr><td>F1 train</td><td>0.4862</td></tr><tr><td>Precision test</td><td>0.47123</td></tr><tr><td>Precision train</td><td>0.72262</td></tr><tr><td>Recall test</td><td>0.49998</td></tr><tr><td>Recall train</td><td>0.50013</td></tr><tr><td>avg epoch time</td><td>15.62509</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>eval time</td><td>5.42477</td></tr><tr><td>loss</td><td>0.19789</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">good-sweep-4</strong> at: <a href='https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/runs/z2q91rkf' target=\"_blank\">https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/runs/z2q91rkf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230816_192027-z2q91rkf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Agent Starting Run: ijx7onn2 with config:\n",
            "\tbatch_size: 128\n",
            "\tdropout: 0.5\n",
            "\thidden_channels: 128\n",
            "\tlr: 0.01\n",
            "\tnum_data_points: 324191\n",
            "\tnum_epochs: 100\n",
            "\tnum_layers: 5\n",
            "wandb: Agent Starting Run: s3n8rdh3 with config:\n",
            "\tbatch_size: 256\n",
            "\tdropout: 0.3\n",
            "\thidden_channels: 128\n",
            "\tlr: 0.01\n",
            "\tnum_data_points: 324191\n",
            "\tnum_epochs: 100\n",
            "\tnum_layers: 5\n",
            "wandb: Agent Starting Run: zxjtxsj4 with config:\n",
            "\tbatch_size: 256\n",
            "\tdropout: 0.3\n",
            "\thidden_channels: 128\n",
            "\tlr: 0.01\n",
            "\tnum_data_points: 324191\n",
            "\tnum_epochs: 100\n",
            "\tnum_layers: 5\n",
            "wandb: Agent Starting Run: bhf7mjrz with config:\n",
            "\tbatch_size: 1014\n",
            "\tdropout: 0.5\n",
            "\thidden_channels: 128\n",
            "\tlr: 0.01\n",
            "\tnum_data_points: 324191\n",
            "\tnum_epochs: 100\n",
            "\tnum_layers: 5\n"
          ]
        }
      ],
      "source": [
        "args['model'] = 'GROVER_FP'\n",
        "# run the sweep\n",
        "wandb.agent(sweep_id, run_sweep(data_splits, args), count=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc6kDkF_CyMn"
      },
      "source": [
        "### Single run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidkubanek\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()\n",
        "# API KEY: 69f641df6e6f0934ab302070cf0b3bcd5399ddd3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LpDabvygfNUy",
        "outputId": "14e4922f-7bcf-4045-874e-c99d26d10de1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b6dcd4cf8df40e2b7c6612d53a343b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667004230002931, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem at: /tmp/ipykernel_35278/1444630434.py 12 <module>\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Create a custom run name dynamically\u001b[39;00m\n\u001b[1;32m     11\u001b[0m run_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_b\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_d\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m'\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_hdim\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m'\u001b[39m\u001b[39mhidden_channels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_ass\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m'\u001b[39m\u001b[39massay_list\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_noout\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m run \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m     13\u001b[0m     name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m     14\u001b[0m     \u001b[39m# Set the project where this run will be logged\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m     project\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGDL_molecular_activity_prediction\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     \u001b[39m# Track hyperparameters and run metadata\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m     config\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     18\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mnum_data_points\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mnum_data_points\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     19\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39massays\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mcell_based_high_hr\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mnum_assays\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mnum_assays\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     23\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mnum_layers\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mnum_layers\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     24\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhidden_channels\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mhidden_channels\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     25\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     26\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     27\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mnum_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mnum_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     28\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m: args[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     29\u001b[0m     })\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1170\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[39massert\u001b[39;00m logger\n\u001b[1;32m   1169\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39minterrupted\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39me)\n\u001b[0;32m-> 1170\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1171\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1172\u001b[0m     error_seen \u001b[39m=\u001b[39m e\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1147\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1145\u001b[0m except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[1;32m   1146\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     run \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39;49minit()\n\u001b[1;32m   1148\u001b[0m     except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n\u001b[1;32m   1149\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:733\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcommunicating run to backend with \u001b[39m\u001b[39m{\u001b[39;00mtimeout\u001b[39m}\u001b[39;00m\u001b[39m second timeout\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    732\u001b[0m run_init_handle \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39minterface\u001b[39m.\u001b[39mdeliver_run(run)\n\u001b[0;32m--> 733\u001b[0m result \u001b[39m=\u001b[39m run_init_handle\u001b[39m.\u001b[39;49mwait(\n\u001b[1;32m    734\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    735\u001b[0m     on_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_progress_init,\n\u001b[1;32m    736\u001b[0m     cancel\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    737\u001b[0m )\n\u001b[1;32m    738\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    739\u001b[0m     run_result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mrun_result\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py:283\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interface\u001b[39m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m MailboxError(\u001b[39m\"\u001b[39m\u001b[39mtransport failed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 283\u001b[0m found, abandoned \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slot\u001b[39m.\u001b[39;49m_get_and_clear(timeout\u001b[39m=\u001b[39;49mwait_timeout)\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m found:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Always update progress to 100% when done\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m on_progress \u001b[39mand\u001b[39;00m progress_handle \u001b[39mand\u001b[39;00m progress_sent:\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py:130\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_and_clear\u001b[39m(\u001b[39mself\u001b[39m, timeout: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Optional[pb\u001b[39m.\u001b[39mResult], \u001b[39mbool\u001b[39m]:\n\u001b[1;32m    129\u001b[0m     found \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout):\n\u001b[1;32m    131\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m             found \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wait\u001b[39m(\u001b[39mself\u001b[39m, timeout: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout\u001b[39m=\u001b[39;49mtimeout)\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "args['assay_list'] = ['2797']\n",
        "args['num_assays'] = 1\n",
        "args['assays_idx'] = find_assay_indeces(args['assay_list'], assay_order)\n",
        "\n",
        "args['model'] = 'GROVER_FP'\n",
        "args['dropout'] = 0.2\n",
        "args['batch_size'] = 256\n",
        "args['hidden_channels'] = 256\n",
        "args['lr'] = 0.01\n",
        "# Create a custom run name dynamically\n",
        "run_name = f\"{args['model']}_b{args['batch_size']}_d{args['dropout']}_hdim{args['hidden_channels']}_ass{args['assay_list'][0]}_noout\"\n",
        "run = wandb.init(\n",
        "    name=run_name,\n",
        "    # Set the project where this run will be logged\n",
        "    project=\"GDL_molecular_activity_prediction\",\n",
        "    # Track hyperparameters and run metadata\n",
        "    config={\n",
        "        'num_data_points': args['num_data_points'],\n",
        "        'assays': 'cell_based_high_hr',\n",
        "        'num_assays': args['num_assays'],\n",
        "\n",
        "        'model': args['model'],\n",
        "        'num_layers': args['num_layers'],\n",
        "        'hidden_channels': args['hidden_channels'],\n",
        "        'dropout': args['dropout'],\n",
        "        'batch_size': args['batch_size'],\n",
        "        'num_epochs': args['num_epochs'],\n",
        "        'lr': args['lr'],\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxCKJ7OjVhKG",
        "outputId": "aba215d1-1f24-465d-fc60-e55a51f592ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: 429 encountered (Filestream rate limit exceeded, retrying in 2.3 seconds.), retrying request\n"
          ]
        }
      ],
      "source": [
        "# create dataset from data_list\n",
        "dataloader = prepare_dataloader(data_splits, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLH8E9KVd1n",
        "outputId": "89058dbd-21ef-4869-db30-d9e197224ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on device: cuda:0\n",
            "Total number of parameters: 2113281\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'lr_decay_factor'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m exp \u001b[39m=\u001b[39m TrainManager(dataloader, args)\n\u001b[1;32m      3\u001b[0m exp\u001b[39m.\u001b[39mtrain(epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, wb_log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "Cell \u001b[0;32mIn[18], line 32\u001b[0m, in \u001b[0;36mTrainManager.__init__\u001b[0;34m(self, dataloader, args, model)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m \u001b[39m# decay learning rate\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler \u001b[39m=\u001b[39m lr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39margs[\u001b[39m'\u001b[39;49m\u001b[39mlr_decay_factor\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr_epoch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lr_decay_factor'"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "exp = TrainManager(dataloader, args)\n",
        "exp.train(epochs=10, log=True, wb_log=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY-oKyawe1vq"
      },
      "outputs": [],
      "source": [
        "exp.analyze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu38fmhbdGgS"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40aba29c28564f819c7d1cafb1235834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e2f3a2781df46e3a47ce8962acd531b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6252098c7f1048f492450291583e301f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e2f3a2781df46e3a47ce8962acd531b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40aba29c28564f819c7d1cafb1235834",
            "value": 0.2042112906153567
          }
        },
        "78a1a347adaa4d4e9949c454776efc5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "927687b91bd14816814a1bf86e971208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78a1a347adaa4d4e9949c454776efc5d",
            "placeholder": "​",
            "style": "IPY_MODEL_ede939aa08c248aa8af7b30e61b4a7ba",
            "value": "0.002 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "a8b130e755244f98b2860b512da44d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_927687b91bd14816814a1bf86e971208",
              "IPY_MODEL_6252098c7f1048f492450291583e301f"
            ],
            "layout": "IPY_MODEL_b7798ae87814431e875a9455657d8ab8"
          }
        },
        "b7798ae87814431e875a9455657d8ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ede939aa08c248aa8af7b30e61b4a7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
