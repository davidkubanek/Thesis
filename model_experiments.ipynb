{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidkubanek/Thesis/blob/main/model_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpnAQeFgIIKA"
      },
      "source": [
        "# CONCERTO architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t1jm2t5MI4af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe763cf-f280-4e10-cc72-b5651d9be2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.3.2\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=2a2c19363062f7b916c0e1f1226bbb0269da58543bf1e7457a1f96e45ec9510d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=a85d81143cb2914769f63503cbb17d5228717236cfb80b7925c2372985f0a33d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.32 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.8\n"
          ]
        }
      ],
      "source": [
        "# for running in colab\n",
        "!pip install dgl\n",
        "!pip install rdkit\n",
        "!pip install torch_geometric\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T69lAzjYIIKB",
        "outputId": "c0f6d24b-1e06-44fc-8c0e-4643f940cb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  plt.rcParams[\"font.family\"] = \"Palatino\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "import wandb\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "# check if cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQK8GKzgKVqk",
        "outputId": "7f1dfc84-85e0-4b15-ec16-ab9a85ab3077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "MG-9VYyW7Dud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "def prepare_datalist(matrix_df, args, graph_fp=True, grover_fp=None):\n",
        "    '''\n",
        "    Convert matrix dataframe to a data_list with pytorch geometric graph data, fingerprints and labels.\n",
        "    Inputs:\n",
        "        matrix_df: dataframe of SMILES, assays and bioactivity labels\n",
        "        args: arguments\n",
        "        graph_fp: if True, includes graph embedding fingerprints into data_list\n",
        "        grover_fp: if True, includes GROVER graph transformer embedding fingerprints into data_list\n",
        "    Outputs:\n",
        "        data_list: list of data objects\n",
        "    '''\n",
        "    # only use subset of data (assays and data points)\n",
        "    assay_list = args['assay_list']\n",
        "    num_assays = args['num_assays']\n",
        "    assay_start = args['assay_start']\n",
        "    num_data_points = args['num_data_points']\n",
        "\n",
        "    # get binary target labels\n",
        "    y = matrix_df[assay_list[assay_start:assay_start+num_assays]].values[:num_data_points]\n",
        "\n",
        "    # get SMILES strings\n",
        "    data = matrix_df['SMILES'].values[:num_data_points]\n",
        "\n",
        "    if graph_fp is True: # add graph fingerprint\n",
        "        GraphDataset = GraphDatasetClass()\n",
        "        # create pytorch geometric graph data list\n",
        "        data_list = GraphDataset.create_pytorch_geometric_graph_data_list_from_smiles_and_labels(data, y)\n",
        "    else: # create simple data_list without graph fingerprint\n",
        "      data_list = []\n",
        "      for label in y:\n",
        "          # construct Pytorch Geometric data object and append to data list\n",
        "          data_list.append(Data(y = label.reshape(1, -1)))\n",
        "\n",
        "    # add fingerprint data to each graph\n",
        "    for i, smile in tqdm(enumerate(data), desc='Adding fingerprints...', total=len(data)):\n",
        "        fp = convert_smile_to_fp_bit_string(smile)\n",
        "        data_list[i].fp = fp\n",
        "\n",
        "\n",
        "    # add grover fingerprint to each graph\n",
        "    if grover_fp is not None:\n",
        "        for i, gfp in tqdm(enumerate(grover_fp['fps'][:args['num_data_points']]), desc='Adding grover embedding...', total=len(data)):\n",
        "          data_list[i].grover_fp = torch.tensor(gfp)\n",
        "\n",
        "    print(f'Example of a graph data object: {data_list[0]}')\n",
        "\n",
        "    return data_list\n",
        "\n",
        "def prepare_dataloader(data_list, args):\n",
        "    '''\n",
        "    Get dataloader dictionary from data_list with desired batch_size\n",
        "    '''\n",
        "    data_list = data_list[:args['num_data_points']]\n",
        "    # split into train and test\n",
        "    train_dataset = data_list[:int(len(data_list)*0.8)]\n",
        "    test_dataset = data_list[int(len(data_list)*0.8):]\n",
        "\n",
        "    # split into train and validation\n",
        "    val_dataset = train_dataset[:int(len(train_dataset)*0.25)]\n",
        "    train_dataset = train_dataset[int(len(train_dataset)*0.25):]\n",
        "\n",
        "    print(f'Number of training graphs: {len(train_dataset)}')\n",
        "    print(f'Number of validation graphs: {len(val_dataset)}')\n",
        "    print(f'Number of test graphs: {len(test_dataset)}')\n",
        "    print(f'Example of a graph data object: {data_list[0]}')\n",
        "\n",
        "    # create data loaders\n",
        "    dataloader = {}\n",
        "    dataloader['train'] = DataLoader(train_dataset, batch_size=args['batch_size'], shuffle=True)\n",
        "    dataloader['val'] = DataLoader(val_dataset, batch_size=args['batch_size'], shuffle=False)\n",
        "    dataloader['test'] = DataLoader(test_dataset, batch_size=args['batch_size'], shuffle=False)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def analyze_dataset(dataset, args):\n",
        "    '''\n",
        "    Analyze the distribution of positive classes in the dataset\n",
        "    '''\n",
        "    positive = []\n",
        "    for i in range(len(dataset)):\n",
        "        positive.append(dataset[i].y[0].sum().item())\n",
        "\n",
        "\n",
        "    num_assays = args['num_assays']\n",
        "    # make histogram of the number of positive\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    # define bins\n",
        "    bins = np.linspace(0, num_assays, num_assays+1)-0.5\n",
        "    plt.hist(positive, bins=bins, alpha=0.5, label='train')\n",
        "    num_assays = args['num_assays']\n",
        "    plt.xlabel(f'# of positive hits in target vector (out of {num_assays})')\n",
        "    plt.ylabel('Number of data points')\n",
        "    plt.title('Histogram of positive class distribution')\n",
        "    plt.show()\n",
        "\n",
        "    for i in range(num_assays+1):\n",
        "        print(f'Number of data points with {i} positive targets: ', (np.array(positive) == i).sum(), f'({(np.array(positive) == i).sum()/len(positive)*100:.2f}%)')\n",
        "\n",
        "def data_explore(dataloader):\n",
        "    '''\n",
        "    Explore the data\n",
        "    '''\n",
        "    # check proportion of positive and negative samples across each assay\n",
        "    pos = torch.zeros(args['num_assays'])\n",
        "    for data in dataloader:  # Iterate in batches over the training dataset\n",
        "        # print('inputs:')\n",
        "        # print(' x:', data.x.shape, '| y:',data.y.shape, '| fp:',data.fp.shape, '| grover:', data.grover_fp.shape)\n",
        "        pos += data.y.sum(axis=0)\n",
        "        #  print(data.y.sum(axis=0))\n",
        "    print('# positive samples:', pos)\n",
        "    print(torch.round((pos/len(dataloader.dataset)*100),decimals=2),'% are positive')\n",
        "\n"
      ],
      "metadata": {
        "id": "eR47vh5vf_Se"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "directory = '/content/drive/MyDrive/Thesis/Data/'\n",
        "\n",
        "# Specify the path where you saved the dictionary\n",
        "load_path = directory + 'datalist_graph.pkl'\n",
        "\n",
        "# Load the dictionary using pickle\n",
        "with open(load_path, 'rb') as f:\n",
        "    data_list = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "bFUFuaaP7MeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "dtbv6Cb4Mes0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {}\n",
        "args['device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# data parameters\n",
        "args['num_data_points'] = 324191 # number of data points to use\n",
        "# args['assay_list'] = cell_based_high_hr #for all: matrix_df.columns.values[1:]\n",
        "args['num_assays'] = 5 # number of assays to use (i.e., no. of output classes)\n",
        "args['assay_start'] = 0 # which assay to start from\n",
        "\n",
        "args['num_node_features'] = 79 # number of node features in graph representation\n",
        "args['grover_fp_dim'] = 5000 #grover_fp['fps'][0].shape[0] # None  # dim of grover fingerprints\n",
        "args['fp_dim'] = 2215 # dim of fingerprints\n",
        "\n",
        "\n",
        "# training parameters\n",
        "args['model'] = 'GCN' # 'GCN', 'GCN_FP', 'FP', 'GROVER', 'GROVER_FP'\n",
        "args['pred_type'] = 'classification' # 'regression', 'classification'\n",
        "args['num_layers'] = 5 # number of layers in MLP\n",
        "args['hidden_channels'] = 64\n",
        "args['dropout'] = 0.1\n",
        "args['batch_size'] = 200\n",
        "args['num_epochs'] = 100\n",
        "args['lr'] = 0.01\n",
        "#args['gradient_clip_norm'] = 1.0\n",
        "#args['network_weight_decay'] = 0.0001\n",
        "#args['lr_decay_factor'] = 0.5\n",
        "\n",
        "# check batch size -> to include examples of classes\n",
        "# dropout maybe higher"
      ],
      "metadata": {
        "id": "xi1iZ2lsMeEt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define hyperparams to sweep"
      ],
      "metadata": {
        "id": "5eEWrR-aTjYI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYWyacYyIIKG"
      },
      "source": [
        "# Models\n",
        "### GCN and GCN_FP\n",
        "- GCN: graph embedding followed by a final classification layer\n",
        "- GCN_FP: graph + fingerprints embedding followed by a final classification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1q43d46hIIKG"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    '''\n",
        "    Define a Graph Convolutional Network (GCN) model architecture.\n",
        "    Can include 'graph' only or 'graph + fingerprints' embedding before final classification layer.\n",
        "    '''\n",
        "    def __init__(self, args):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "\n",
        "        num_node_features = args['num_node_features']\n",
        "        hidden_channels = args['hidden_channels']\n",
        "        num_classes = args['num_assays']\n",
        "        if args['model'] == 'GCN_FP':\n",
        "            fp_dim = args['fp_dim']\n",
        "        else:\n",
        "            fp_dim = 0\n",
        "\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin = Linear(hidden_channels + fp_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch, fp=None):\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # if also using fingerprints\n",
        "        if fp is not None:\n",
        "            # reshape fp to batch_size x fp_dim\n",
        "            fp = fp.reshape(x.shape[0], -1)\n",
        "            # concatenate graph node embeddings with fingerprint\n",
        "            # print('BEFORE CONCAT x:',x.shape, 'fp:', fp.shape)\n",
        "            x = torch.cat([x, fp], dim=1)\n",
        "            # print('AFTER CONCAT x:',x.shape)\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cENu4SMIIKG"
      },
      "source": [
        "### FP, GROVER and GROVER_FP\n",
        "- FP: fingerprints embedding followed by a final classification layer\n",
        "- GROVER: graph transformer embedding followed by a final classification layer\n",
        "- GROVER_FP: graph transformer + fingerprints embedding followed by a final classification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PXTwqghIIIKG"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LinearBlock(nn.Module):\n",
        "\t\"\"\" basic block in an MLP, with dropout and batch norm \"\"\"\n",
        "\n",
        "\tdef __init__(self, in_feats, out_feats, dropout=0.1):\n",
        "\t\tsuper(LinearBlock, self).__init__()\n",
        "\t\tself.linear = nn.Linear(in_feats, out_feats)\n",
        "\t\tself.bn = nn.BatchNorm1d(out_feats)\n",
        "\t\tself.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# ReLU activation, batch norm, dropout on layer\n",
        "\t\treturn self.bn(self.dropout(F.relu(self.linear(x))))\n",
        "\n",
        "def construct_mlp(in_dim, out_dim, hidden_dim, hidden_layers, dropout=0.1):\n",
        "\t\"\"\"\n",
        "\tConstructs an MLP with specified dimensions.\n",
        "\t\t- total number of layers = hidden_layers + 1 (the + 1 is for the output linear)\n",
        "\t\t- no activation/batch norm/dropout on output layer\n",
        "\t\"\"\"\n",
        "\n",
        "\tassert hidden_layers >= 1, hidden_layers\n",
        "\tmlp_list = []\n",
        "\tmlp_list.append(LinearBlock(in_dim,hidden_dim,dropout=dropout))\n",
        "\tfor i in range(hidden_layers-1):\n",
        "\t\tmlp_list.append(LinearBlock(hidden_dim,hidden_dim,dropout=dropout))\n",
        "\n",
        "\t# no activation/batch norm/dropout on output layer\n",
        "\tmlp_list.append(nn.Linear(hidden_dim,out_dim))\n",
        "\tmlp = nn.Sequential(*mlp_list)\n",
        "\treturn mlp\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\t'''\n",
        "\tMLP with optional Grover fingerprints.\n",
        "\tCustomizable number of layers, hidden dimensions, and dropout.\n",
        "\t'''\n",
        "\tdef __init__(self, args):\n",
        "\n",
        "\t\tsuper(MLP, self).__init__()\n",
        "\n",
        "\t\tself.model_type = args['model']\n",
        "\t\tself.fp_dim = args['fp_dim'] # can be 0\n",
        "\t\tself.grover_fp_dim = args['grover_fp_dim'] # can be 0\n",
        "\t\tself.hidden_dim = args['hidden_channels']\n",
        "\t\tself.output_dim = args['num_assays']\n",
        "\t\tself.num_layers = args['num_layers']\n",
        "\t\tself.dropout = args['dropout']\n",
        "\n",
        "\t\tassert self.model_type in ['FP','GROVER','GROVER_FP'], f'model type not supported: {self.model_type}'\n",
        "\n",
        "\t\tif self.model_type == 'FP':\n",
        "\t\t\tself.grover_fp_dim = 0\n",
        "\t\telif self.model_type == 'GROVER':\n",
        "\t\t\tself.fp_dim = 0\n",
        "\n",
        "\t\tself.ff_layers = construct_mlp(\n",
        "\t\t\tself.fp_dim + self.grover_fp_dim,\n",
        "\t\t\tself.output_dim,\n",
        "\t\t\tself.hidden_dim,\n",
        "\t\t\tself.num_layers,\n",
        "\t\t\tself.dropout\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, data):\n",
        "\n",
        "\n",
        "\t\tif self.model_type == 'FP': # only fp is used\n",
        "\t\t\tfingerprints = data.fp\n",
        "\t\t\t# reshape fp to batch_size x fp_dim\n",
        "\t\t\tfingerprints = fingerprints.reshape(int(fingerprints.shape[0]/self.fp_dim), -1)\n",
        "\n",
        "\t\t\toutput = self.ff_layers(fingerprints)\n",
        "\n",
        "\t\telif self.model_type == 'GROVER': # only grover is used\n",
        "\t\t\t# reshape grover_fp to batch_size x grover_fp_dim\n",
        "\t\t\tgrover_fp = data.grover_fp\n",
        "\t\t\tgrover_fp = grover_fp.reshape(int(grover_fp.shape[0]/self.grover_fp_dim), -1)\n",
        "\n",
        "\t\t\toutput = self.ff_layers(grover_fp)\n",
        "\n",
        "\t\telif self.model_type == 'GROVER_FP': #grover and fp are concatenated\n",
        "\t\t\tfingerprints = data.fp\n",
        "\t\t\t# reshape fp to batch_size x fp_dim\n",
        "\t\t\tfingerprints = fingerprints.reshape(int(fingerprints.shape[0]/self.fp_dim), -1)\n",
        "\t\t\t# reshape grover_fp to batch_size x grover_fp_dim\n",
        "\t\t\tgrover_fp = data.grover_fp\n",
        "\t\t\tgrover_fp = grover_fp.reshape(int(grover_fp.shape[0]/self.grover_fp_dim), -1)\n",
        "\n",
        "\t\t\toutput = self.ff_layers(torch.cat([fingerprints, grover_fp], dim=1))\n",
        "\n",
        "\n",
        "\t\treturn output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMXuJkTGIIKH"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "A3SbXTXlIIKH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "class TrainManager:\n",
        "\n",
        "    def __init__(self, dataloader, args, model=None):\n",
        "\n",
        "        self.args = args\n",
        "        self.num_assays = args['num_assays']\n",
        "        self.num_node_features = args['num_node_features']\n",
        "        self.hidden_channels = args['hidden_channels']\n",
        "\n",
        "        if not model:\n",
        "            # initialize model depending on model type\n",
        "            if args['model'] in ['GCN','GCN_FP']:\n",
        "                self.model = GCN(args)\n",
        "            elif args['model'] in ['FP','GROVER','GROVER_FP']:\n",
        "              self.model = MLP(args)\n",
        "        else:\n",
        "            self.model = model\n",
        "\n",
        "        self.model.to(args['device'])\n",
        "        print(\"Model is on device:\", next(self.model.parameters()).device)\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=args['lr'])\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.curr_epoch = 0\n",
        "\n",
        "        # logging\n",
        "        self.eval_metrics = {}\n",
        "        self.eval_metrics['loss'] = []\n",
        "        self.eval_metrics['acc_train'] = []\n",
        "        self.eval_metrics['acc_test'] = []\n",
        "        self.eval_metrics['auc_train'] = []\n",
        "        self.eval_metrics['auc_test'] = []\n",
        "        self.eval_metrics['precision_train'] = []\n",
        "        self.eval_metrics['precision_test'] = []\n",
        "        self.eval_metrics['recall_train'] = []\n",
        "        self.eval_metrics['recall_test'] = []\n",
        "        self.eval_metrics['f1_train'] = []\n",
        "        self.eval_metrics['f1_test'] = []\n",
        "\n",
        "\n",
        "    def train(self, epochs=100, log=False, wb_log=False):\n",
        "        '''\n",
        "        Train the model for a given number of epochs.\n",
        "        '''\n",
        "\n",
        "        self.wb_log = wb_log\n",
        "\n",
        "        epoch_times = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            self.model.train()\n",
        "            cum_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Iterate in batches over the training dataset\n",
        "            for data in tqdm(self.dataloader['train'], desc=f'Epoch [{self.curr_epoch}/{epochs}]', total=int(len(self.dataloader['train'].dataset)/self.args['batch_size'])):\n",
        "\n",
        "                data = data.to(self.args['device'])\n",
        "\n",
        "                # forward pass based on model type\n",
        "                if self.args['model'] == 'GCN':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch)\n",
        "                elif self.args['model'] == 'GCN_FP':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch, fp=data.fp)\n",
        "                elif self.args['model'] in ['FP','GROVER','GROVER_FP']:\n",
        "                    out = self.model(data)\n",
        "\n",
        "                # data.y = data.y.unsqueeze(1)\n",
        "                # print('data.y:',torch.tensor(data.y).squeeze(1)[0])\n",
        "                # print('out:', out[0])\n",
        "\n",
        "                # if run with graph data\n",
        "                # loss = self.criterion(out, data.y)\n",
        "                loss = self.criterion(out, torch.tensor(data.y).squeeze(1).float())  # Compute the loss.\n",
        "                loss.backward()  # Derive gradients.\n",
        "                self.optimizer.step()  # Update parameters based on gradients.\n",
        "                self.optimizer.zero_grad()  # Clear gradients.\n",
        "                cum_loss += loss.item()\n",
        "\n",
        "            self.eval_metrics['loss'].append(cum_loss/len(self.dataloader['train']))\n",
        "            if wb_log is True:\n",
        "              wandb.log({\"loss\": cum_loss/len(self.dataloader['train'])})\n",
        "\n",
        "            epoch_time = time.time() - start_time\n",
        "            epoch_times.append(epoch_time)\n",
        "\n",
        "            if log:\n",
        "                # evaluate\n",
        "                acc_train, auc_train, precision_train, recall_train, f1_train = self.eval(self.dataloader['train'])\n",
        "                acc_test, auc_test, precision_test, recall_test, f1_test = self.eval(self.dataloader['val'])\n",
        "\n",
        "\n",
        "                self.eval_metrics['acc_train'].append(acc_train)\n",
        "                self.eval_metrics['acc_test'].append(acc_test)\n",
        "                self.eval_metrics['auc_train'].append(auc_train)\n",
        "                self.eval_metrics['auc_test'].append(auc_test)\n",
        "                self.eval_metrics['precision_train'].append(precision_train)\n",
        "                self.eval_metrics['precision_test'].append(precision_test)\n",
        "                self.eval_metrics['recall_train'].append(recall_train)\n",
        "                self.eval_metrics['recall_test'].append(recall_test)\n",
        "                self.eval_metrics['f1_train'].append(f1_train)\n",
        "                self.eval_metrics['f1_test'].append(f1_test)\n",
        "\n",
        "                if wb_log is True:\n",
        "                    wandb.log({\"AUC train\": auc_train, \"AUC test\": auc_test, \"F1 train\": f1_train, \"F1 test\": f1_test, \"Precision train\": precision_train, \"Precision test\": precision_test, \"Recall train\": recall_train, \"Recall test\": recall_test})\n",
        "\n",
        "\n",
        "                if epoch % 10 == 0:\n",
        "                    print(f'Epoch: {self.curr_epoch}, Loss: {loss.item():.4f}, Train AUC: {auc_train:.4f}, Test AUC: {auc_test:.4f}')\n",
        "                    print(f'                        Train F1: {f1_train:.4f}, Test F1: {f1_test:.4f}')\n",
        "\n",
        "            self.curr_epoch += 1\n",
        "\n",
        "\n",
        "\n",
        "        self.avg_epoch_time = np.mean(epoch_times)\n",
        "        if wb_log is True:\n",
        "            wandb.log({\"avg epoch time\": self.avg_epoch_time})\n",
        "\n",
        "    def eval(self, loader):\n",
        "        '''\n",
        "        Evaluate the model on a given dataset (train/val/test).\n",
        "        '''\n",
        "        start_time = time.time()\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        # print(\"Model is on device for eval:\", next(exp.model.parameters()).device)\n",
        "\n",
        "        correct = 0\n",
        "\n",
        "        gts = []\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "\n",
        "                data = data.to(self.args['device'])\n",
        "\n",
        "                # forward pass based on model type\n",
        "                if self.args['model'] == 'GCN':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch)\n",
        "                elif self.args['model'] == 'GCN_FP':\n",
        "                    out = self.model(data.x, data.edge_index, data.batch, fp=data.fp)\n",
        "                elif self.args['model'] in ['FP','GROVER','GROVER_FP']:\n",
        "                    out = self.model(data)\n",
        "\n",
        "                # convert out to binary\n",
        "                data.y = torch.tensor(data.y).squeeze(1).float()\n",
        "                pred = torch.round(torch.sigmoid(out))\n",
        "                preds.append(torch.round(torch.sigmoid(out)).tolist())\n",
        "                gts.append(data.y.tolist())\n",
        "                # print('pred:', pred)\n",
        "                # print('data.y:', data.y)\n",
        "                # print('data.y eval:',data.y.shape)\n",
        "                # data.y = data.y.unsqueeze(1)\n",
        "                correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        preds = [b[i] for b in preds for i in range(len(b))]\n",
        "        gts = [b[i] for b in gts for i in range(len(b))]\n",
        "\n",
        "        auc = roc_auc_score(gts, preds)\n",
        "        # Calculate macro-averaged precision, recall, and F1 Score\n",
        "        precision = precision_score(gts, preds, average='macro', zero_division=0)\n",
        "        recall = recall_score(gts, preds, average='macro', zero_division=0)\n",
        "        f1 = f1_score(gts, preds, average='macro', zero_division=0)\n",
        "\n",
        "\n",
        "        acc = correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
        "\n",
        "        self.eval_time = time.time() - start_time\n",
        "\n",
        "        if self.wb_log is True:\n",
        "            wandb.log({\"eval time\": self.eval_time})\n",
        "\n",
        "        return acc, auc, precision, recall, f1\n",
        "\n",
        "\n",
        "\n",
        "    def analyze(self):\n",
        "        '''\n",
        "        Plot the model performance.\n",
        "        '''\n",
        "\n",
        "        # plot side by side\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        ax1.plot(self.eval_metrics['loss'])\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title('Losses')\n",
        "\n",
        "        ax2.plot(self.eval_metrics['auc_train'], label='train')\n",
        "        ax2.plot(self.eval_metrics['auc_test'], label='test')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('AUC')\n",
        "        ax2.set_title('Area Under Curve')\n",
        "        ax2.legend()\n",
        "        # make main title for the whole plot\n",
        "        if args['model'] in ['GCN', 'GCN_FP']:\n",
        "            plt.suptitle(f'Model: {self.args[\"model\"]} | Node feats: {self.args[\"num_node_features\"]}, Hidden dim: {self.args[\"hidden_channels\"]}, Dropout: {self.args[\"dropout\"]}, Num data points: {self.args[\"num_data_points\"]}, Num assays: {self.args[\"num_assays\"]}, Num epochs: {self.curr_epoch}')\n",
        "        elif args['model'] in ['FP', 'GROVER', 'GROVER_FP']:\n",
        "            plt.suptitle(f'Model: {self.args[\"model\"]} | Num layers: {self.args[\"num_layers\"]}, Hidden dim: {self.args[\"hidden_channels\"]}, Dropout: {self.args[\"dropout\"]}, Num data points: {self.args[\"num_data_points\"]}, Num assays: {self.args[\"num_assays\"]}, Num epochs: {self.curr_epoch}')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def save_model(self, folder, filename, save_weights=True, save_logs=True):\n",
        "        print('saving experiment...')\n",
        "\n",
        "        filename += f'_{self.curr_epoch}e'\n",
        "        if save_weights:\n",
        "            torch.save(self.model.state_dict(), os.path.join(folder, filename+'.pt'))\n",
        "\n",
        "        #if save_logs:\n",
        "\n",
        "    def load_model(self, folder, filename):\n",
        "        print('loading model...')\n",
        "        self.model.load_state_dict(torch.load(os.path.join(folder, filename+'.pt')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxwqEHtDIIKH"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "parameters_dict = {\n",
        "    'batch_size': {\n",
        "        'values': [512, 1014]\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.3, 0.5]\n",
        "        },\n",
        "    }\n",
        "\n",
        "parameters_dict.update({\n",
        "    'num_data_points': {\n",
        "        'value': args['num_data_points']},\n",
        "    'num_epochs': {\n",
        "        'value': args['num_epochs']},\n",
        "    'num_layers': {\n",
        "        'value': args['num_layers']},\n",
        "    'hidden_channels': {\n",
        "        'value': args['hidden_channels']},\n",
        "    'lr': {\n",
        "        'value': args['lr']}\n",
        "    })\n",
        "sweep_config['parameters'] = parameters_dict"
      ],
      "metadata": {
        "id": "q4KsLRLXN9KG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"GDL_molecular_activity_prediction\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UMXJz4sNuCo",
        "outputId": "97cdebd8-6afc-4b3f-9d2b-62188acf726f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: vcsw0x6q\n",
            "Sweep URL: https://wandb.ai/davidkubanek/GDL_molecular_activity_prediction/sweeps/vcsw0x6q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = f\"{args['model']}_b{args['batch_size']}_d{args['dropout']}\"\n",
        "run = wandb.init(\n",
        "    name=run_name,\n",
        "    # Set the project where this run will be logged\n",
        "    project=\"GDL_molecular_activity_prediction\",\n",
        "    # Track hyperparameters and run metadata\n",
        "    config={\n",
        "        'num_data_points': args['num_data_points'],\n",
        "        'assays': 'cell_based_high_hr',\n",
        "        'num_assays': args['num_assays'],\n",
        "\n",
        "        'model': args['model'],\n",
        "        'num_layers': args['num_layers'],\n",
        "        'hidden_channels': args['hidden_channels'],\n",
        "        'dropout': args['dropout'],\n",
        "        'batch_size': args['batch_size'],\n",
        "        'num_epochs': args['num_epochs'],\n",
        "        'lr': args['lr'],\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633,
          "referenced_widgets": [
            "2b16f029c27440f2be92673180de9299",
            "2ce36aae348b476898df091e34fd5249",
            "2b5a9530385448848956dff34c032293",
            "521bdc22ef714f57bbee2981f706f0b7",
            "8c6a7d5e44644f1c84feb42f25a0b24e",
            "617788ceb3384c95b224166daeff7c7d",
            "8aa959a896314053b37123c72230c80d",
            "5366814f7a634a9da615f34a8a262ccc",
            "0d91bf43ead7404a9b2d1b875efa16b3",
            "8fb789ee81e949a1b42171124ab32765",
            "05b4b049a7d14eeb9f0eec55cd78d77f",
            "df7cd29248f94b34ba8fc4f8cadb82e9",
            "5addb800cc164c378ab3d0ebce44aae2",
            "cc70d28156e341a49d308d4269b4df6d",
            "e8efd58a39ea422d9287b0c8a0fbc54b",
            "f5355291788140d1a98e4a0f46f4975c"
          ]
        },
        "id": "LpDabvygfNUy",
        "outputId": "a1f77a33-3bb0-4173-cff3-5fa4427deeb3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:dh9sxi3l) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b16f029c27440f2be92673180de9299"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:dh9sxi3l). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669476049992228, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d91bf43ead7404a9b2d1b875efa16b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem at: <ipython-input-87-0825b9aa8e0f> 2 <cell line: 2>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-0825b9aa8e0f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{args['model']}_b{args['batch_size']}_d{args['dropout']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m run = wandb.init(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Set the project where this run will be logged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GDL_molecular_activity_prediction\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mrun_init_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeliver_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         result = run_init_handle.wait(\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mon_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_progress_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mMailboxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transport failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabandoned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;31m# Always update progress to 100% when done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset from data_list\n",
        "dataloader = prepare_dataloader(data_list, args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxCKJ7OjVhKG",
        "outputId": "2991de1b-8b6a-4eb0-d281-cb54301d4d26"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training graphs: 6000\n",
            "Number of validation graphs: 2000\n",
            "Number of test graphs: 2000\n",
            "Example of a graph data object: Data(y=[1, 5], fp=[2215], grover_fp=[5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "exp = TrainManager(dataloader, args)\n",
        "exp.train(epochs=20, log=True, wb_log=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLH8E9KVd1n",
        "outputId": "7a312a01-2152-4a38-a60c-d0159afc81f8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/20]: 30it [00:00, 34.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.3058, Train AUC: 0.5000, Test AUC: 0.5000\n",
            "                        Train F1: 0.0000, Test F1: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/20]: 30it [00:00, 40.26it/s]\n",
            "Epoch [2/20]: 30it [00:00, 46.28it/s]\n",
            "Epoch [3/20]: 30it [00:00, 58.56it/s]\n",
            "Epoch [4/20]: 30it [00:00, 59.81it/s]\n",
            "Epoch [5/20]: 30it [00:00, 54.85it/s]\n",
            "Epoch [6/20]: 30it [00:00, 55.33it/s]\n",
            "Epoch [7/20]: 30it [00:00, 56.02it/s]\n",
            "Epoch [8/20]: 30it [00:00, 56.90it/s]\n",
            "Epoch [9/20]: 30it [00:00, 56.34it/s]\n",
            "Epoch [10/20]: 30it [00:00, 55.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.2753, Train AUC: 0.5004, Test AUC: 0.5000\n",
            "                        Train F1: 0.0014, Test F1: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [11/20]: 30it [00:00, 50.89it/s]\n",
            "Epoch [12/20]: 30it [00:00, 46.17it/s]\n",
            "Epoch [13/20]: 30it [00:00, 43.41it/s]\n",
            "Epoch [14/20]: 30it [00:00, 44.39it/s]\n",
            "Epoch [15/20]: 30it [00:00, 54.17it/s]\n",
            "Epoch [16/20]: 30it [00:00, 56.48it/s]\n",
            "Epoch [17/20]: 30it [00:00, 55.13it/s]\n",
            "Epoch [18/20]: 30it [00:00, 56.62it/s]\n",
            "Epoch [19/20]: 30it [00:00, 56.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp.analyze()"
      ],
      "metadata": {
        "id": "IY-oKyawe1vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_sweep(data_list, args):\n",
        "    # Create a custom run name dynamically\n",
        "    run_name = f\"{args['model']}_b{args['batch_size']}_d{args['dropout']}\"\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=wandb.config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "        args['batch_size'] = config.batch_size\n",
        "        args['dropout'] = config.dropout\n",
        "\n",
        "        # create dataset from data_list\n",
        "        dataloader = prepare_dataloader(data_list, args)\n",
        "\n",
        "        # train model\n",
        "        exp = TrainManager(dataloader, args)\n",
        "        exp.train(epochs=10, log=True, wb_log=True)\n"
      ],
      "metadata": {
        "id": "BinziYUTQwGY"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args['model'] = 'GROVER_FP'\n",
        "# run the sweep\n",
        "wandb.agent(sweep_id, run_sweep(data_list, args), count=4)"
      ],
      "metadata": {
        "id": "NxiWVecC85c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "yu38fmhbdGgS"
      },
      "execution_count": 92,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b16f029c27440f2be92673180de9299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ce36aae348b476898df091e34fd5249",
              "IPY_MODEL_2b5a9530385448848956dff34c032293"
            ],
            "layout": "IPY_MODEL_521bdc22ef714f57bbee2981f706f0b7"
          }
        },
        "2ce36aae348b476898df091e34fd5249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6a7d5e44644f1c84feb42f25a0b24e",
            "placeholder": "​",
            "style": "IPY_MODEL_617788ceb3384c95b224166daeff7c7d",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "2b5a9530385448848956dff34c032293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa959a896314053b37123c72230c80d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5366814f7a634a9da615f34a8a262ccc",
            "value": 1
          }
        },
        "521bdc22ef714f57bbee2981f706f0b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6a7d5e44644f1c84feb42f25a0b24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "617788ceb3384c95b224166daeff7c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aa959a896314053b37123c72230c80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5366814f7a634a9da615f34a8a262ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d91bf43ead7404a9b2d1b875efa16b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fb789ee81e949a1b42171124ab32765",
              "IPY_MODEL_05b4b049a7d14eeb9f0eec55cd78d77f"
            ],
            "layout": "IPY_MODEL_df7cd29248f94b34ba8fc4f8cadb82e9"
          }
        },
        "8fb789ee81e949a1b42171124ab32765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5addb800cc164c378ab3d0ebce44aae2",
            "placeholder": "​",
            "style": "IPY_MODEL_cc70d28156e341a49d308d4269b4df6d",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "05b4b049a7d14eeb9f0eec55cd78d77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8efd58a39ea422d9287b0c8a0fbc54b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5355291788140d1a98e4a0f46f4975c",
            "value": 0.08348758414999793
          }
        },
        "df7cd29248f94b34ba8fc4f8cadb82e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5addb800cc164c378ab3d0ebce44aae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc70d28156e341a49d308d4269b4df6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8efd58a39ea422d9287b0c8a0fbc54b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5355291788140d1a98e4a0f46f4975c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}