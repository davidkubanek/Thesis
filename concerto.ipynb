{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCERTO architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "plt.rcParams[\"font.family\"] = \"Palatino\"\n",
    "\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "import warnings\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a_train_epoch(args, epoch, model, data_loader, mut_loss_criterion, carc_loss_criterion, optimizer):\n",
    "    model.train()\n",
    "    train_meter_carc = Meter()\n",
    "    train_meter_mut = Meter()\n",
    "    losses = []\n",
    "    mut_losses = []\n",
    "    carc_losses = []\n",
    "\n",
    "    if type(data_loader.dataset) == dgl.data.utils.Subset:\n",
    "        use_carc_prob = data_loader.dataset.dataset.use_carc_prob\n",
    "    elif type(data_loader.dataset) == GraphCancerMolecules or type(data_loader.dataset) == SelfiesCancerMolecules:\n",
    "        use_carc_prob = data_loader.dataset.use_carc_prob\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    for batch_id, batch_data in enumerate(data_loader):\n",
    "        batch_data = to_device(batch_data, args[\"device\"])\n",
    "        # evaluate model for this batch for both carcinogenic and mutagenic labels\n",
    "        logits = model(batch_data)\n",
    "        # Mask non-existing labels\n",
    "\n",
    "        # get carcinogenic logits + labels based on the loss function\n",
    "        if type(carc_loss_criterion) == torch.nn.modules.loss.BCEWithLogitsLoss:\n",
    "            carc_logits = torch.masked_select(logits[:, 1], batch_data['carc_mask'])\n",
    "\n",
    "            if use_carc_prob:\n",
    "                carc_labels = torch.masked_select(batch_data[\"carc_prob\"], batch_data['carc_mask'])\n",
    "            else:\n",
    "                carc_labels = torch.masked_select(batch_data[\"carc_label\"], batch_data['carc_mask'])\n",
    "            carc_logging = torch.masked_select(batch_data[\"carc_label\"], batch_data['carc_mask'])\n",
    "\n",
    "        elif type(carc_loss_criterion) == torch.nn.modules.loss.MSELoss:\n",
    "            carc_logits = torch.masked_select(logits[:, 1], batch_data['carc_mask_continuous'])\n",
    "            carc_labels = torch.masked_select(batch_data[\"carc_continuous\"], batch_data['carc_mask_continuous'])\n",
    "            carc_logging = carc_labels\n",
    "\n",
    "        elif type(carc_loss_criterion) == torch.nn.modules.loss.CrossEntropyLoss:\n",
    "            new_mask = batch_data['carc_mask_continuous'].view(-1, 1).expand(logits[:, 1:6].shape)\n",
    "\n",
    "            carc_logits = torch.masked_select(logits[:, 1:6], new_mask).view(-1, 5)\n",
    "            carc_labels = torch.masked_select(batch_data[\"carc_label_multi\"], batch_data['carc_mask_multi'])\n",
    "            carc_logging = carc_labels\n",
    "\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        # Get mutagenic logits\n",
    "        mut_logits = torch.masked_select(logits[:, 0], batch_data['mut_mask'])\n",
    "        mut_labels = torch.masked_select(batch_data[\"mut_label\"], batch_data['mut_mask'])\n",
    "\n",
    "        # In case batch does not contain any carcinogenic labels set loss manually to 0\n",
    "        if args['use_carc_loss'] and len(carc_logits) > 0:\n",
    "            carc_loss = carc_loss_criterion(carc_logits, carc_labels).mean()\n",
    "            train_meter_carc.update(carc_logits.view(-1, 1), carc_logging.view(-1, 1))\n",
    "        else:\n",
    "            carc_loss = torch.tensor(0)\n",
    "\n",
    "        if args['use_mut_loss'] and len(mut_logits) > 0:\n",
    "            mut_loss = mut_loss_criterion(mut_logits, mut_labels).mean()\n",
    "            train_meter_mut.update(mut_logits.view(-1, 1), mut_labels.view(-1, 1))\n",
    "        else:\n",
    "            mut_loss = torch.tensor(0)\n",
    "\n",
    "        # Take weighted average of mut_loss and carc loss\n",
    "        loss = carc_loss * (1 - args['mut_loss_ratio']) + mut_loss * args['mut_loss_ratio']\n",
    "\n",
    "        # Zero out the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backpropagate loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip loss\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args[\"gradient_clip_norm\"])\n",
    "\n",
    "        # apply changes to weights\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        carc_losses.append(carc_loss.item())\n",
    "        mut_losses.append(mut_loss.item())\n",
    "\n",
    "        if batch_id + 1 % args['print_every'] == 0:\n",
    "            print('epoch {:d}/{:d}, batch {:d}/{:d}'.format(\n",
    "                epoch + 1, args['num_epochs'], batch_id + 1, len(data_loader)))\n",
    "\n",
    "        if args['use_carc_loss']:\n",
    "            train_carc_metric, train_carc_metric_name, train_carc_metric2, train_carc_metric_name2 = perform_eval(\n",
    "                carc_loss_criterion, train_meter_carc)\n",
    "        else:\n",
    "            train_carc_metric = np.nan\n",
    "            train_carc_metric_name = np.nan\n",
    "            train_carc_metric2 = np.nan\n",
    "            train_carc_metric_name2 = np.nan\n",
    "\n",
    "        if args['use_mut_loss']:\n",
    "            train_mut_metric, train_mut_metric_name, train_mut_metric2, train_mut_metric_name2 = perform_eval(\n",
    "                mut_loss_criterion, train_meter_mut)\n",
    "        else:\n",
    "            train_mut_metric = np.nan\n",
    "            train_mut_metric_name = np.nan\n",
    "            train_mut_metric2 = np.nan\n",
    "            train_mut_metric_name2 = np.nan\n",
    "\n",
    "        train_loss = np.nanmean(losses)\n",
    "        train_mut_loss = np.nanmean(mut_losses)\n",
    "        train_carc_loss = np.nanmean(carc_losses)\n",
    "\n",
    "        return train_loss, train_carc_loss, train_mut_loss,\\\n",
    "               train_mut_metric, train_mut_metric_name, train_mut_metric2, train_mut_metric_name2, \\\n",
    "               train_carc_metric, train_carc_metric_name, train_carc_metric2, train_carc_metric_name2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, args, mut_loss_criterion, carc_loss_criterion, train_loader, val_loader, note=''):\n",
    "    '''\n",
    "    Performs the training loop for the model with either carc or mut datasets with corresponding losses\n",
    "    '''\n",
    "    stopper = construct_stopper(args)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=args['lr'], weight_decay=args['network_weight_decay'])\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=args['lr_decay_factor'])\n",
    "\n",
    "    for epoch in range(args['num_epochs']):\n",
    "        # run a training epoch\n",
    "        train_loss, train_carc_loss, train_mut_loss,\\\n",
    "        train_mut_metric, train_mut_metric_name, train_mut_metric2, train_mut_metric_name2, \\\n",
    "        train_carc_metric, train_carc_metric_name, train_carc_metric2, train_carc_metric_name2 = run_a_train_epoch(\n",
    "            args, epoch, model, train_loader, mut_loss_criterion, carc_loss_criterion, optimizer)\n",
    "\n",
    "        # Validation and early stop\n",
    "        val_carc_metric, val_carc_metric_name, val_carc_metric2, val_carc_metric_name2,\\\n",
    "        val_mut_metric, val_mut_metric_name, val_mut_metric2, val_mut_metric_name2, \\\n",
    "        val_loss, val_carc_loss, val_mut_loss, \\\n",
    "        performance_df = run_an_eval_epoch(\n",
    "            args, model, val_loader, mut_loss_criterion, carc_loss_criterion\n",
    "        )\n",
    "\n",
    "        if args['early_stopping_metric'][1] == 'carc':\n",
    "            if args['early_stopping_metric'][0] == 'roc_auc_score':\n",
    "                val_score = val_carc_metric\n",
    "                if val_carc_metric_name != 'roc_auc_score':\n",
    "                    raise ValueError\n",
    "\n",
    "            elif args['early_stopping_metric'][0] == 'pearson_r2':\n",
    "                val_score = val_carc_metric\n",
    "                if val_carc_metric_name != 'pearson_r2':\n",
    "                    raise ValueError\n",
    "\n",
    "            elif args['early_stopping_metric'][0] == 'rmse':\n",
    "                val_score = val_carc_metric2\n",
    "                if val_carc_metric_name2 != 'rmse':\n",
    "                    raise ValueError\n",
    "\n",
    "            elif args['early_stopping_metric'][0] == 'validation_loss':\n",
    "                val_score = val_loss\n",
    "\n",
    "            else:\n",
    "                raise ValueError\n",
    "        elif args['early_stopping_metric'][1] == 'mut':\n",
    "            if args['early_stopping_metric'][0] == 'roc_auc_score':\n",
    "                val_score = val_mut_metric\n",
    "                if val_mut_metric_name != 'roc_auc_score':\n",
    "                    raise ValueError\n",
    "            else:\n",
    "                raise ValueError\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        scheduler.step(val_score)\n",
    "        early_stop = stopper.step(val_score, model)\n",
    "\n",
    "        print(f\"Training: epoch   {epoch + 1:d}/{args['num_epochs']:d}, \"\n",
    "              f\"training loss     {train_loss:.3f}, \"\n",
    "              f\"mut_{train_mut_metric_name} {train_mut_metric:.3f} \"\n",
    "              f\"mut_{train_mut_metric_name2} {train_mut_metric2:.3f} \"\n",
    "              f\"carc_{train_carc_metric_name} {train_carc_metric:.3f} \"\n",
    "              f\"carc_{train_carc_metric_name2} {train_carc_metric2:.3f} \"\n",
    "              )\n",
    "        print(f\"Validation: epoch {epoch + 1:d}/{args['num_epochs']:d}, \"\n",
    "              f\"validation loss   {val_loss:.3f}, \"\n",
    "              f\"mut_{val_mut_metric_name} {val_mut_metric:.3f} \"\n",
    "              f\"mut_{val_mut_metric_name2} {val_mut_metric2:.3f} \"\n",
    "              f\"carc_{val_carc_metric_name} {val_carc_metric:.3f} \"\n",
    "              f\"carc_{val_carc_metric_name2} {val_carc_metric2:.3f} \\n\"\n",
    "              )\n",
    "\n",
    "        if args[\"use_wandb\"]:\n",
    "            wandb.log({\n",
    "                f\"epoch{note}\": epoch + 1,\n",
    "                f\"training_carcinogenic_loss{note}\": train_carc_loss,\n",
    "                f\"training_mutagenic_loss{note}\": train_mut_loss,\n",
    "                f\"training_loss{note}\": train_loss,\n",
    "                f\"training_mut_{train_mut_metric_name}{note}\": train_mut_metric,\n",
    "                f\"training_mut_{train_mut_metric_name2}{note}\": train_mut_metric2,\n",
    "                f\"training_carc_{train_carc_metric_name}{note}\": train_carc_metric,\n",
    "                f\"training_carc_{train_carc_metric_name2}{note}\": train_carc_metric2,\n",
    "\n",
    "                f\"validation_loss{note}\": val_loss,\n",
    "                f\"validation_carc_loss{note}\": val_carc_loss,\n",
    "                f\"validation_mut_loss{note}\": val_mut_loss,\n",
    "                f\"validation_carc_{val_carc_metric_name}{note}\": val_carc_metric,\n",
    "                f\"validation_carc_{val_carc_metric_name2}{note}\": val_carc_metric2,\n",
    "                f\"validation_mut_{val_mut_metric_name}{note}\": val_mut_metric,\n",
    "                f\"validation_mut_{val_mut_metric_name2}{note}\": val_mut_metric2,\n",
    "            })\n",
    "\n",
    "        if early_stop:\n",
    "            break\n",
    "    stopper.load_checkpoint(model)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_mode(args, mut_loss_criterion, carc_loss_criterion, held_out_test_carc_loss_criterion):\n",
    "    '''\n",
    "    Executes the simple training loop if no pre-training is required or executes the pre-training loop\n",
    "    '''\n",
    "\n",
    "    train_loader, val_loader, test_loader, held_out_test_data_loader, data_feats = load_data(args)\n",
    "\n",
    "    model = get_model(args, data_feats)\n",
    "    model.to(args['device'])\n",
    "\n",
    "    wandb_run = set_up_wandb(model, args, name=args['run'], group=args['group_name'])\n",
    "    print(data_feats)\n",
    "    print(model)\n",
    "\n",
    "    if not args['mut_pre_training']:\n",
    "        model = training_loop(model, args, mut_loss_criterion, carc_loss_criterion, train_loader, val_loader)\n",
    "\n",
    "    else:\n",
    "        for j in range(args['num_mut_pre_training_loop']):\n",
    "            # perform mutagenicity pre-training cycle loop\n",
    "            model = mutagenicity_pre_training(\n",
    "                args, train_loader, val_loader, model, mut_loss_criterion, carc_loss_criterion)\n",
    "\n",
    "            if j < args['num_mut_pre_training_loop'] - 1:\n",
    "                summary_dict = end_of_training_evaluation(\n",
    "                    model, args, mut_loss_criterion, carc_loss_criterion, held_out_test_carc_loss_criterion,\n",
    "                    val_loader, test_loader, held_out_test_data_loader, note=f\"_{j}\", save_data=False\n",
    "                )\n",
    "\n",
    "    summary_dict = end_of_training_evaluation(\n",
    "        model, args, mut_loss_criterion, carc_loss_criterion, held_out_test_carc_loss_criterion,\n",
    "        val_loader, test_loader, held_out_test_data_loader\n",
    "    )\n",
    "\n",
    "    wandb.log(summary_dict)\n",
    "    return summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    data, held_out_test_data = get_datasets(args)\n",
    "    train, val, test = split_data(data)\n",
    "    # data features from data\n",
    "    data_feats = data.get_data_feats()\n",
    "    collate_fn = data.get_collate_fn()\n",
    "\n",
    "    train_loader = construct_data_loader(train, args, collate_fn)\n",
    "    val_loader = construct_data_loader(val, args, collate_fn)\n",
    "    test_loader = construct_data_loader(test, args, collate_fn)\n",
    "    held_out_test_data_loader = construct_data_loader(held_out_test_data, args, collate_fn)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, held_out_test_data_loader, data_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutagenicity_pre_training(args, train_loader, val_loader, model, mut_loss_criterion, carc_loss_criterion, note=''):\n",
    "    '''\n",
    "    Performs mutagenicity pre-training and carciniogenicity training iteration\n",
    "    terminate upon early stopping\n",
    "    '''\n",
    "    train_mut_loader, train_carc_loader = split_loader_into_carc_and_mut(train_loader, args)\n",
    "\n",
    "    # mut loss only\n",
    "    args['use_carc_loss'] = False\n",
    "    args['use_mut_loss'] = True\n",
    "    args['early_stopping_metric'] = ('roc_auc_score', 'mut')\n",
    "    # train model on mut data with mut loss\n",
    "    model = training_loop(\n",
    "        model, args, mut_loss_criterion, carc_loss_criterion, train_mut_loader, val_loader, note=note)\n",
    "\n",
    "    # carc loss only\n",
    "    args['use_carc_loss'] = True\n",
    "    args['use_mut_loss'] = False\n",
    "\n",
    "    if args['train_carc_loss_fnc'] == 'MSE':\n",
    "        args['early_stopping_metric'] = ('rmse', 'carc')\n",
    "    elif args['train_carc_loss_fnc'] == 'BCE':\n",
    "        args['early_stopping_metric'] = ('roc_auc_score', 'carc')\n",
    "    elif args['train_carc_loss_fnc'] == 'CE':\n",
    "        args['early_stopping_metric'] = ('validation_loss', 'carc')\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    # train model on carc data with carc loss\n",
    "    model = training_loop(\n",
    "        model, args, mut_loss_criterion, carc_loss_criterion, train_carc_loader, val_loader, note=note)\n",
    "    # will do this K times\n",
    "    args['use_carc_loss'] = True\n",
    "    args['use_mut_loss'] = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetClass(Dataset):\n",
    "\tdef __init__(self, out_feats=1, drop_ionic=True, min_carbon_count=0, fraction_of_data=1, use_carc_prob=False, carc_percentile_to_drop=0):\n",
    "\t\tself.out_feats = out_feats\n",
    "\t\tself.drop_ionic = drop_ionic\n",
    "\t\tself.min_carbon_count = min_carbon_count\n",
    "\t\tself.fraction_of_data = fraction_of_data\n",
    "\t\tself.use_carc_prob = use_carc_prob\n",
    "\t\tself.carc_percentile_to_drop = carc_percentile_to_drop\n",
    "\t\t\n",
    "\tdef load_carc_cpdb(cls):\n",
    "\t\tcpdb = pd.read_csv(\n",
    "\t\t\t'Data/concerto data/cpdb_aggergated.csv',\n",
    "\t\t\tusecols=['smiles', 'td50_log_harmonic', 'cas', 'carc_class', 'carc_class_multi']\n",
    "\t\t)\n",
    "\t\tcpdb['smiles'] = cls.smiles_standardize(cpdb['smiles'].values)\n",
    "\t\tcpdb = cpdb[cpdb['smiles'].notnull()]\n",
    "\t\tcpdb.rename(columns={'td50_log_harmonic': 'td50'}, inplace=True)\n",
    "\t\tassert cpdb['smiles'].duplicated().sum() == 0, \\\n",
    "\t\t\tcpdb[cpdb['smiles'].duplicated(keep=False)].sort_values('smiles').to_string()\n",
    "\t\tcpdb['source'] = 'cpdb'\n",
    "\t\treturn cpdb\n",
    "\t\n",
    "\tdef load_mut_hansen(cls):\n",
    "\t\tames_df = pd.read_csv('Data/concerto data/hansen_2009_ames.smi', sep='\\t', names=['smiles', 'cas', 'class'])\n",
    "\t\tames_df['smiles'] = cls.smiles_standardize(ames_df['smiles'].values)\n",
    "\t\tames_df = ames_df[ames_df['smiles'].notnull()]\n",
    "\t\tames_df.rename(columns={'class': 'mut_class'}, inplace=True)\n",
    "\t\tames_df.drop(columns='cas', inplace=True)\n",
    "\t\tames_df = ames_df[~ames_df.duplicated(['smiles', 'mut_class'])]\n",
    "\t\tassert ames_df['smiles'].duplicated().sum() == 0, \\\n",
    "\t\t\tames_df[ames_df['smiles'].duplicated(keep=False)].sort_values('smiles').to_string()\n",
    "\t\tames_df['source'] = 'hansen'\n",
    "\t\treturn ames_df\n",
    "    \n",
    "\n",
    "\tdef smiles_standardize(cls, smiles):\n",
    "\t\tnew_smiles = []\n",
    "\t\tfor smile in smiles:\n",
    "\t\t\tif pd.isnull(smile):\n",
    "\t\t\t\tnew_smiles.append(None)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# Generate the molecule from smile string\n",
    "\t\t\tmol = Chem.MolFromSmiles(smile)\n",
    "\t\t\t# If the smile string is null then continue\n",
    "\t\t\tif pd.isnull(mol):\n",
    "\t\t\t\tnew_smiles.append(None)\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_smiles.append(Chem.MolToSmiles(mol,canonical=True,isomericSmiles=False,allBondsExplicit=False))\n",
    "\t\treturn new_smiles\n",
    "\t\n",
    "\tdef count_num_carbons(cls, smile):\n",
    "\t\tmol = Chem.MolFromSmiles(smile)\n",
    "\t\tnum_c = 0\n",
    "\t\tfor atom in mol.GetAtoms():\n",
    "\t\t\tif atom.GetSymbol().upper() == 'C':\n",
    "\t\t\t\tnum_c += 1\n",
    "\t\treturn num_c\n",
    "\t\n",
    "\tdef load_data(self):\n",
    "\t\t# Loaded data should not overlap mut_hansn and carc_cpdb since they are the two primary training data sources\n",
    "\t\tmut = self.load_mut_hansen()\n",
    "\t\tcarc = self.load_carc_cpdb()\n",
    "\n",
    "\t\tcarc_datasets = []\n",
    "\t\tmut_datasets = []\n",
    "\t\t\n",
    "\t\tcarc_datasets.append(carc)\n",
    "\n",
    "\t\t# if 'carc_ccris' in self.carc_datasets:\n",
    "\t\t# \ttemp = self.load_carc_ccris()\n",
    "\t\t# \t# drop samples that are in training data by default cpdb & carc_pred_el\n",
    "\t\t# \ttemp = temp[~temp['smiles'].isin(carc['smiles'])]\n",
    "\t\t# \tcarc_datasets.append(temp)\n",
    "\n",
    "\t\tmut_datasets.append(mut)\n",
    "\n",
    "\t\tif mut_datasets:\n",
    "\t\t\tmut = pd.concat(mut_datasets)\n",
    "\t\telse:\n",
    "\t\t\tmut = pd.DataFrame(columns=mut.columns)\n",
    "\n",
    "\t\tif carc_datasets:\n",
    "\t\t\tcarc = pd.concat(carc_datasets)\n",
    "\t\telse:\n",
    "\t\t\tcarc = pd.DataFrame(columns=carc.columns)\n",
    "\n",
    "\t\t# check for duplicates\n",
    "\t\tif mut['smiles'].duplicated().sum() != 0:\n",
    "\t\t\twarnings.warn(f\"duplicated samples {mut['smiles'].duplicated().sum()} contained in mutagenicity data \"\n",
    "\t\t\t\t\t\t  f\"from {mut_datasets}\\n\"\n",
    "\t\t\t\t\t\t  f\" {mut[mut['smiles'].duplicated(keep=False)].sort_values('smiles').head().to_string()}\")\n",
    "\t\t\tmut.sort_values(['smiles', 'mut_class'], ascending=False)\n",
    "\t\t\tmut = mut[~mut.duplicated('smiles')]\n",
    "\n",
    "\t\tif carc['smiles'].duplicated().sum() != 0:\n",
    "\t\t\twarnings.warn(f\"duplicated samples {carc['smiles'].duplicated().sum()} contained in carcinogenicity data \"\n",
    "\t\t\t\t\t\t  f\"from {carc_datasets}\\n\"\n",
    "\t\t\t\t\t\t  f\" {carc[carc['smiles'].duplicated(keep=False)].sort_values('smiles').head().to_string()}\")\n",
    "\t\t\tcarc = carc[~carc.duplicated('smiles')]\n",
    "\n",
    "\t\t# merge the mut and carc datasets\n",
    "\t\tdf = pd.merge(mut, carc, how='outer', on='smiles')\n",
    "\t\tdf['source'] = df['source_x'].fillna('') + ',' + df['source_y'].fillna('')\n",
    "\t\tdf.drop(columns=['source_x', 'source_y'], inplace=True)\n",
    "\n",
    "\t\trequired_columns = ['td50', 'carc_class', 'mut_class', 'carc_class_multi']\n",
    "\t\tfor column in required_columns:\n",
    "\t\t\tif column not in df.columns:\n",
    "\t\t\t\tdf[column] = np.nan\n",
    "\n",
    "\t\tif self.drop_ionic:\n",
    "\t\t\tdf = df[~df['smiles'].str.contains('\\.')]\n",
    "\n",
    "\t\tdf['carbon_count'] = [self.count_num_carbons(x) for x in df['smiles'].values]\n",
    "\t\tif self.min_carbon_count:\n",
    "\t\t\tdf = df[df['carbon_count'] >= self.min_carbon_count]\n",
    "\t\t\t\n",
    "\t\t# Shuffle the data\n",
    "\t\tindex = np.arange(len(df))\n",
    "\t\tnp.random.seed(1337)\n",
    "\t\tnp.random.shuffle(index)\n",
    "\t\tdf = df.iloc[index].reset_index(drop=True)\n",
    "\n",
    "\t\t# Log of Betas that were fitted using a cox regression model\n",
    "\t\tif self.carc_percentile_to_drop > 0:\n",
    "\t\t\t# cleave off the top percentile\n",
    "\t\t\tlowest_td_50_val = np.nanpercentile(df['td50'].values, self.carc_percentile_to_drop)\n",
    "\t\t\tmask = df[df['td50'] <= lowest_td_50_val].index\n",
    "\t\t\tdf.loc[mask, 'td50'] = lowest_td_50_val\n",
    "\n",
    "\t\tbetas = np.log((np.log(2) / df[\"td50\"].values))\n",
    "\n",
    "\t\t# standardize\n",
    "\t\tbeta_standardized = (betas - np.nanmean(betas)) / np.nanstd(betas)\n",
    "\t\t# normalize\n",
    "\t\tbeta_normalized = betas - np.nanmin(betas)\n",
    "\t\tbeta_normalized = beta_normalized / np.nanmax(beta_normalized)\n",
    "\n",
    "\t\tdf['beta_standardized'] = beta_standardized\n",
    "\t\tdf['beta_normalized'] = beta_normalized\n",
    "\n",
    "\t\tif self.fraction_of_data < 1:\n",
    "\t\t\tnew_data_len = int(len(df) * self.fraction_of_data)\n",
    "\t\t\tdf = df.iloc[:new_data_len]\n",
    "\n",
    "\t\t#save the resulting dataframe\n",
    "\t\tself.df = df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_smile_to_fp_bit_string(self, smile):\n",
    "        \"\"\"\n",
    "        RDFKIT Morgan and MACCSS are default fingerprints. Torsion and atom pairs are optional\n",
    "        \"\"\"\n",
    "        # RDFKIT\n",
    "        x = Chem.MolFromSmiles(smile)\n",
    "        fp1 = Chem.RDKFingerprint(x, fpSize=self.fp_nbits)\n",
    "        # MACCSS substructure\n",
    "        fp2 = MACCSkeys.GenMACCSKeys(x)\n",
    "        # Morgan\n",
    "        fp_hashes = []\n",
    "        fp3 = AllChem.GetHashedMorganFingerprint(x, 2, nBits=self.fp_nbits)\n",
    "        fp3_array = np.zeros((0,), dtype=np.int8)\n",
    "        DataStructs.ConvertToNumpyArray(fp3, fp3_array)\n",
    "        fp_hashes.append(fp3_array)\n",
    "\n",
    "        # Hashed atom pairs\n",
    "        if self.atom_pairs_fingerprints:\n",
    "            fp4 = AllChem.GetHashedAtomPairFingerprint(x, nBits=self.fp_nbits)\n",
    "            fp4_array = np.zeros((0,), dtype=np.int8)\n",
    "            DataStructs.ConvertToNumpyArray(fp4, fp4_array)\n",
    "            fp_hashes.append(fp4_array)\n",
    "\n",
    "        # Torsion fingerprints?\n",
    "        if self.torsion_fingerprints:\n",
    "            fp5 = AllChem.GetHashedTopologicalTorsionFingerprint(x, nBits=self.fp_nbits)\n",
    "            fp5_array = np.zeros((0,), dtype=np.int8)\n",
    "            DataStructs.ConvertToNumpyArray(fp5, fp5_array)\n",
    "            fp_hashes.append(fp5_array)\n",
    "\n",
    "        fp = fp1.ToBitString() + fp2.ToBitString()\n",
    "        fp = np.array(list(fp)).astype(np.int8)\n",
    "        fp = np.concatenate([fp] + fp_hashes)\n",
    "        fp = torch.tensor(fp).to(torch.float32)\n",
    "        return fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:11:05] SMILES Parse Error: syntax error while parsing: NNC(=O)CNC(=O)\\C=N\\#N\n",
      "[09:11:05] SMILES Parse Error: Failed parsing SMILES 'NNC(=O)CNC(=O)\\C=N\\#N' for input: 'NNC(=O)CNC(=O)\\C=N\\#N'\n",
      "[09:11:05] SMILES Parse Error: syntax error while parsing: O=C1NC(=O)\\C(=N/#N)\\C=N1\n",
      "[09:11:05] SMILES Parse Error: Failed parsing SMILES 'O=C1NC(=O)\\C(=N/#N)\\C=N1' for input: 'O=C1NC(=O)\\C(=N/#N)\\C=N1'\n",
      "[09:11:05] SMILES Parse Error: syntax error while parsing: NC(=O)CNC(=O)\\C=N\\#N\n",
      "[09:11:05] SMILES Parse Error: Failed parsing SMILES 'NC(=O)CNC(=O)\\C=N\\#N' for input: 'NC(=O)CNC(=O)\\C=N\\#N'\n",
      "[09:11:05] SMILES Parse Error: syntax error while parsing: CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O\n",
      "[09:11:05] SMILES Parse Error: Failed parsing SMILES 'CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O' for input: 'CCCCN(CC(O)C1=C\\C(=N/#N)\\C(=O)C=C1)N=O'\n",
      "[09:11:05] SMILES Parse Error: syntax error while parsing: NC(COC(=O)\\C=N/#N)C(=O)O\n",
      "[09:11:05] SMILES Parse Error: Failed parsing SMILES 'NC(COC(=O)\\C=N/#N)C(=O)O' for input: 'NC(COC(=O)\\C=N/#N)C(=O)O'\n",
      "[09:11:05] SMILES Parse Error: syntax error while parsing: CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O\n",
      "[09:11:05] SMILES Parse Error: Failed parsing SMILES 'CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O' for input: 'CCN(CC(O)C1=CC(=O)\\C(=N\\#N)\\C=C1)N=O'\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:11:06] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetClass()\n",
    "dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>mut_class</th>\n",
       "      <th>cas</th>\n",
       "      <th>td50</th>\n",
       "      <th>carc_class_multi</th>\n",
       "      <th>carc_class</th>\n",
       "      <th>source</th>\n",
       "      <th>carbon_count</th>\n",
       "      <th>beta_standardized</th>\n",
       "      <th>beta_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>CN1CCc2cc3c(c4c2C1Cc1ccccc1-4)OCO3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>CCOP(=O)(Oc1ccc([N+](=O)[O-])cc1)c1ccccc1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>O=C=Nc1cccc2c(N=C=O)cccc12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>Cc1c(N=O)cccc1[N+](=O)[O-]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>O=C1OC(O)C(C(Cl)Br)=C1Cl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>O=[N+]([O-])c1cc(N(CCO)CCO)ccc1NCCO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33229-34-4</td>\n",
       "      <td>10.932522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hansen,cpdb</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.397473</td>\n",
       "      <td>0.138117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NC(CS)C(=O)NCC(=O)O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>Cc1ccc(N=Nc2c(O)ccc3ccccc23)c(C)c1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>CC1SCC(C(=O)NC(Cc2c[nH]cn2)C(=O)N2CCCC2C(N)=O)...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>COc1nc2cccc(CBr)c2nc1OC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hansen,</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles  mut_class  \\\n",
       "3299                 CN1CCc2cc3c(c4c2C1Cc1ccccc1-4)OCO3        1.0   \n",
       "2897          CCOP(=O)(Oc1ccc([N+](=O)[O-])cc1)c1ccccc1        1.0   \n",
       "977                          O=C=Nc1cccc2c(N=C=O)cccc12        0.0   \n",
       "3231                         Cc1c(N=O)cccc1[N+](=O)[O-]        0.0   \n",
       "1117                           O=C1OC(O)C(C(Cl)Br)=C1Cl        1.0   \n",
       "4442                O=[N+]([O-])c1cc(N(CCO)CCO)ccc1NCCO        1.0   \n",
       "68                                  NC(CS)C(=O)NCC(=O)O        1.0   \n",
       "5493                 Cc1ccc(N=Nc2c(O)ccc3ccccc23)c(C)c1        1.0   \n",
       "2331  CC1SCC(C(=O)NC(Cc2c[nH]cn2)C(=O)N2CCCC2C(N)=O)...        0.0   \n",
       "3599                            COc1nc2cccc(CBr)c2nc1OC        1.0   \n",
       "\n",
       "             cas       td50  carc_class_multi  carc_class       source  \\\n",
       "3299         NaN        NaN               NaN         NaN      hansen,   \n",
       "2897         NaN        NaN               NaN         NaN      hansen,   \n",
       "977          NaN        NaN               NaN         NaN      hansen,   \n",
       "3231         NaN        NaN               NaN         NaN      hansen,   \n",
       "1117         NaN        NaN               NaN         NaN      hansen,   \n",
       "4442  33229-34-4  10.932522               1.0         0.0  hansen,cpdb   \n",
       "68           NaN        NaN               NaN         NaN      hansen,   \n",
       "5493         NaN        NaN               NaN         NaN      hansen,   \n",
       "2331         NaN        NaN               NaN         NaN      hansen,   \n",
       "3599         NaN        NaN               NaN         NaN      hansen,   \n",
       "\n",
       "      carbon_count  beta_standardized  beta_normalized  \n",
       "3299            18                NaN              NaN  \n",
       "2897            14                NaN              NaN  \n",
       "977             12                NaN              NaN  \n",
       "3231             7                NaN              NaN  \n",
       "1117             5                NaN              NaN  \n",
       "4442            12          -0.397473         0.138117  \n",
       "68               5                NaN              NaN  \n",
       "5493            18                NaN              NaN  \n",
       "2331            17                NaN              NaN  \n",
       "3599            11                NaN              NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give random draw of data\n",
    "dataset.df.sample(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
